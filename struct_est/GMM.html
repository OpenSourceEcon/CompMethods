

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>18. Generalized Method of Moments Estimation &#8212; Computational Methods for Economists using Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'struct_est/GMM';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="19. Simulated Method of Moments Estimation" href="SMM.html" />
    <link rel="prev" title="17. Maximum Likelihood Estimation" href="MLE.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/CompMethodsLogo.png" class="logo__image only-light" alt="Computational Methods for Economists using Python - Home"/>
    <script>document.write(`<img src="../_static/CompMethodsLogo.png" class="logo__image only-dark" alt="Computational Methods for Economists using Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Computational Methods for Economists using Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contributor Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../contrib/contributing.html">Contributor Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Coding in Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../python/intro.html">1. Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/StandardLibrary.html">2. Python Standard Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/ExceptionsIO.html">3. Exception Handling and File Input/Output</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/OOP.html">4. Object Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/NumPy.html">5. NumPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/Pandas.html">6. Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/Matplotlib.html">7. Matplotlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/SciPy.html">8. SciPy: Root finding, minimizing, interpolation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/DocStrings.html">9. Docstrings and Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/UnitTesting.html">10. Unit Testing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Git and GitHub</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../git/intro.html">11. Git and GitHub</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Empirical Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic_empirics/BasicEmpirMethods.html">12. Basic Empirical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_empirics/LogisticReg.html">13. Logistic Regression Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic_ml/ml_intro.html">14. Basic Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Nets and Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../deep_learn/intro.html">15. Neural Nets and Deep Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Structural Estimation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">16. Introduction to Structural Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="MLE.html">17. Maximum Likelihood Estimation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">18. Generalized Method of Moments Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="SMM.html">19. Simulated Method of Moments Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="paper.html">20. Writing a Structural Estimation Paper</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendix/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/appendix.html">Appendix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../CompMethods_references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/OpenSourceEcon/CompMethods/blob/main/docs/book/struct_est/GMM.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/OpenSourceEcon/CompMethods" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenSourceEcon/CompMethods/issues/new?title=Issue%20on%20page%20%2Fstruct_est/GMM.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/struct_est/GMM.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../_sources/struct_est/GMM.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Generalized Method of Moments Estimation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-vs-mle-strengths-and-weaknesses">18.1. GMM vs. MLE: Strengths and weaknesses</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-strengths">18.1.1. MLE strengths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-weaknesses">18.1.2. MLE weaknesses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-strengths">18.1.3. GMM strengths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-weaknesses">18.1.4. GMM weaknesses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-questions-when-deciding-between-mle-and-gmm">18.1.5. Key questions when deciding between MLE and GMM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gmm-estimator">18.2. The GMM estimator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-weighting-matrix-w">18.3. The weighting matrix (W)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-identity-matrix-w-i">18.3.1. The identity matrix (W=I)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-step-variance-covariance-estimator-of-w">18.3.2. Two-step variance-covariance estimator of W</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iterated-variance-covariance-estimator-of-w">18.3.3. Iterated variance-covariance estimator of W</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#newey-west-consistent-estimator-of-omega-and-w">18.3.4. Newey-West consistent estimator of <span class="math notranslate nohighlight">\(\Omega\)</span> and W</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-covariance-estimator-of-hat-theta">18.4. Variance-Covariance Estimator of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-examples">18.5. Code Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-a-truncated-normal-to-intermediate-macroeconomics-test-scores">18.5.1. Fitting a truncated normal to intermediate macroeconomics test scores</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#two-moments-identity-weighting-matrix">18.5.1.1. Two moments, identity weighting matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#two-moments-two-step-weighting-matrix">18.5.1.2. Two moments, two-step weighting matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#four-moments-identity-weighting-matrix">18.5.1.3. Four moments, identity weighting matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#four-moments-two-step-weighting-matrix">18.5.1.4. Four moments, two-step weighting matrix</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unconditional-and-conditional-expectations-instruments-and-moments">18.5.2. Unconditional and conditional expectations, instruments, and moments</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinary-least-squares-ols-overidentification">18.5.2.1. Ordinary least squares (OLS): overidentification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-by-moment-condition-exact-identification">18.5.2.2. Linear regression by moment condition: exact identification</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brock-and-mirman-1972-dynamic-macroeconomic-model">18.5.3. Brock and Mirman (1972) dynamic macroeconomic model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hansen-and-singleton-1982">18.5.4. Hansen and Singleton (1982)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#secgmm-ident">18.6. Identification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">18.7. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#footnotes">18.8. Footnotes</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="generalized-method-of-moments-estimation">
<span id="chap-gmm"></span><h1><span class="section-number">18. </span>Generalized Method of Moments Estimation<a class="headerlink" href="#generalized-method-of-moments-estimation" title="Permalink to this heading">#</a></h1>
<p>This chapter describes the generalized method of moments (GMM) estimation method. All data and images from this chapter can be found in the data directory (<a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/tree/main/data/gmm/">./data/gmm/</a>) and images directory (<a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/tree/main/images/gmm/">./images/gmm/</a>) for the GitHub repository for this online book.</p>
<section id="gmm-vs-mle-strengths-and-weaknesses">
<span id="secgmm-gmmvmle"></span><h2><span class="section-number">18.1. </span>GMM vs. MLE: Strengths and weaknesses<a class="headerlink" href="#gmm-vs-mle-strengths-and-weaknesses" title="Permalink to this heading">#</a></h2>
<p>A paper by <span id="id1">[<a class="reference internal" href="../CompMethods_references.html#id31" title="Jeffrey C. Fuhrer, George R. Moore, and Scott Schuh. Estimating the linear-quadratic inventory model: maximum likelihood versus generalized method of moments. Journal of Monetary Economics, 35(1):115-157, February 1995.">Fuhrer <em>et al.</em>, 1995</a>]</span> studies the accuracy and efficiency of the maximum likelihood (ML) estimator versus the generalized method of moments (GMM) estimator in the context of a simple linear-quadratic inventory model. They find that ML has some very nice properties over GMM in small samples when the model is simple. In the spirit of the <span id="id2">[<a class="reference internal" href="../CompMethods_references.html#id31" title="Jeffrey C. Fuhrer, George R. Moore, and Scott Schuh. Estimating the linear-quadratic inventory model: maximum likelihood versus generalized method of moments. Journal of Monetary Economics, 35(1):115-157, February 1995.">Fuhrer <em>et al.</em>, 1995</a>]</span> paper, we list the strengths and weaknesses of MLE vs. GMM more generally. I recommend you read the introduction to <span id="id3">[<a class="reference internal" href="../CompMethods_references.html#id31" title="Jeffrey C. Fuhrer, George R. Moore, and Scott Schuh. Estimating the linear-quadratic inventory model: maximum likelihood versus generalized method of moments. Journal of Monetary Economics, 35(1):115-157, February 1995.">Fuhrer <em>et al.</em>, 1995</a>]</span>. This paper provides big support for maximum likelihood estimation over generalized method of moments. However, GMM estimation allows for less strong assumptions.</p>
<ul class="simple">
<li><p>GMM almost always rejects the model (Hansen J-test)</p></li>
<li><p>MLE supports the model, kind of by assumption</p></li>
<li><p>“Monte Carlo experiments reveal that the GMM estimates are often biased (apparently due to poor instruments), statistically insignificant, economically implausible, and dynamically unstable.”</p></li>
<li><p>“The ML estimates are generally unbiased (even in misspecifipd models), statistically significant, economically plausible, and dynamically stable.”</p></li>
<li><p>“Asymptotic standard errors for ML are 3 to 15 times smaller than for GMM.”</p></li>
</ul>
<section id="mle-strengths">
<span id="secgmm-mlestr"></span><h3><span class="section-number">18.1.1. </span>MLE strengths<a class="headerlink" href="#mle-strengths" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>More statistical significance. In general, MLE provides more statistical significance for parameter estimates than does GMM. This comes from the strong distributional assumptions that are necessary for the ML estimates.</p></li>
<li><p>ML estimates are less sensitive to parameter or model normalizations than are GMM estimates.</p></li>
<li><p>ML estimates have nice small sample properties. ML estimates have less bias and more efficiency with small data samples than GMM estimates in many cases.</p></li>
</ul>
</section>
<section id="mle-weaknesses">
<span id="secgmm-mlewk"></span><h3><span class="section-number">18.1.2. </span>MLE weaknesses<a class="headerlink" href="#mle-weaknesses" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>MLE requires strong distributional assumptions. For MLE, the data generating process (DGP) must be completely specified. This assumes a lot of knowledge about the DGP. This assumption is likely almost always wrong.</p></li>
<li><p>MLE is very difficult in rational expectations models. This is because the consistency of beliefs induces a nonlinearity in the likelihood function that makes it difficult to find the global optimum.</p></li>
<li><p>MLE is very difficult in nonlinear models. The likelihood function can become highly nonlinear in MLE even if the model is linear when the data are irregular. This difficulty is multiplied when the model itself is more complicated and nonlinear.</p></li>
</ul>
</section>
<section id="gmm-strengths">
<span id="secgmm-gmmstr"></span><h3><span class="section-number">18.1.3. </span>GMM strengths<a class="headerlink" href="#gmm-strengths" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>GMM allows for most flexible identification. GMM estimates can be identified by any set of moments from the data as long as you have at least as many moments as you have parameters to estimate and that those moments are independent enough to identify the parameters. (And the parameters are independent enough of each other to be separately identified.)</p></li>
<li><p>Good large sample properties. The GMM estimator is strongly consistent and asymptotically normal. GMM will likely be the best estimator if you have a lot of data.</p></li>
<li><p>GMM requires minimal assumptions about the DGP. In GMM, you need not specify the distributions of the error terms in your model of the DGP. This is often a strength, given that most error are not observed and most models are gross approximations of the true DGP.</p></li>
</ul>
</section>
<section id="gmm-weaknesses">
<span id="secgmm-gmmwk"></span><h3><span class="section-number">18.1.4. </span>GMM weaknesses<a class="headerlink" href="#gmm-weaknesses" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>GMM estimates are usually less statistically significant than ML estimates. This comes from the minimal distributional assumptions. GMM parameter estimates usually are measured with more error.</p></li>
<li><p>GMM estimates can be sensitive to normalizations of the model or parameters.</p></li>
<li><p>GMM estimates have bad small sample properties. GMM estimates can have large bias and inefficiency in small samples.</p></li>
</ul>
</section>
<section id="key-questions-when-deciding-between-mle-and-gmm">
<span id="secgmm-keyqst"></span><h3><span class="section-number">18.1.5. </span>Key questions when deciding between MLE and GMM<a class="headerlink" href="#key-questions-when-deciding-between-mle-and-gmm" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>How much data is available for the estimation? Large data samples will make GMM relatively more attractive than MLE because of the nice large sample properties of GMM and fewer required assumptions on the model.</p></li>
<li><p>How complex is the model? Linear models or quadratic models are much easier to do using MLE than are more highly nonlinear models. Rational expectations models (macroeconomics) create an even more difficult level of nonlinearity that pushes you toward GMM estimation.</p></li>
<li><p>How comfortable are you making strong distributional assumptions? MLE requires a complete specification of all distributional assumptions of the model DGP. If you think these assumptions are too strong, you should use GMM.</p></li>
</ul>
</section>
</section>
<section id="the-gmm-estimator">
<span id="secgmm-gmmest"></span><h2><span class="section-number">18.2. </span>The GMM estimator<a class="headerlink" href="#the-gmm-estimator" title="Permalink to this heading">#</a></h2>
<p>GMM was first formalized by <span id="id4">[<a class="reference internal" href="../CompMethods_references.html#id37" title="Lars Peter Hansen. Large sample properties of generalized method of moments estimators. Econometrica, 50(4):1029-1054, July 1982.">Hansen, 1982</a>]</span>. A strength of GMM estimation is that the econometrician can remain completely agnostic as to the distribution of the random variables in the DGP. For identification, the econometrician simply needs at least as many moment conditions from the data as he has parameters to estimate.</p>
<p>A <em>moment</em> of the data is broadly defined as any statistic that summarizes the data to some degree. A data moment could be as narrow as an individual observation from the data or as broad as the sample average. GMM estimates the parameters of a model or data generating process to make the model moments as close as possible to the corresponding data moments. See <span id="id5">[<a class="reference internal" href="../CompMethods_references.html#id23" title="Russell Davidson and James G. MacKinnon. Econometric Theory and Methods. Oxford University Press, 2004.">Davidson and MacKinnon, 2004</a>]</span>, chapter 9 for a more detailed treatment of GMM. The estimation methods of linear least squares, nonlinear least squares, generalized least squares, and instrumental variables estimation are all specific cases of the more general GMM estimation method.</p>
<p>Let <span class="math notranslate nohighlight">\(m(x)\)</span> be an <span class="math notranslate nohighlight">\(R\times 1\)</span> vector of moments from the real world data <span class="math notranslate nohighlight">\(x\)</span>, where <span class="math notranslate nohighlight">\(m_r(x)\)</span> is the <span class="math notranslate nohighlight">\(r\)</span>th data moment. And let <span class="math notranslate nohighlight">\(x\)</span> be an <span class="math notranslate nohighlight">\(N\times K\)</span> matrix of data with <span class="math notranslate nohighlight">\(K\)</span> columns representing <span class="math notranslate nohighlight">\(K\)</span> variables and <span class="math notranslate nohighlight">\(N\)</span> observations.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-datamomvec">
<span class="eqno">(18.1)<a class="headerlink" href="#equation-eqgmm-gmmest-datamomvec" title="Permalink to this equation">#</a></span>\[    m(x) \equiv \left[m_1(x), m_2(x), ...m_R(x)\right]^T\]</div>
<p>Let the model DGP be characterized as <span class="math notranslate nohighlight">\(F(x,\theta)=0\)</span>, where <span class="math notranslate nohighlight">\(F\)</span> is a vector of equations, each of which is a function of the data <span class="math notranslate nohighlight">\(x\)</span> and the <span class="math notranslate nohighlight">\(K\times 1\)</span> parameter vector <span class="math notranslate nohighlight">\(\theta\)</span>. Then define <span class="math notranslate nohighlight">\(m(x|\theta)\)</span> as a vector of <span class="math notranslate nohighlight">\(R\)</span> moments from the model that correspond to the real-world moment vector <span class="math notranslate nohighlight">\(m(x)\)</span>, where <span class="math notranslate nohighlight">\(m_r(x|\theta)\)</span> is the <span class="math notranslate nohighlight">\(r\)</span>th model moment.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-modmomvec">
<span class="eqno">(18.2)<a class="headerlink" href="#equation-eqgmm-gmmest-modmomvec" title="Permalink to this equation">#</a></span>\[    m(x|\theta) \equiv \left[m_1(x|\theta), m_2(x|\theta), ...m_R(x|\theta)\right]^T\]</div>
<p>Note that GMM requires both real world data <span class="math notranslate nohighlight">\(x\)</span> and moments that can be calculated from both the data <span class="math notranslate nohighlight">\(m(x)\)</span> and from the model <span class="math notranslate nohighlight">\(m(x|\theta)\)</span> in order to estimate the parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span>. There is also a stochastic way to generate moments from the model, which we discuss later in our section on Simulated Method of Moments (SMM).</p>
<p>The GMM approach of estimating the parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> is to choose <span class="math notranslate nohighlight">\(\theta\)</span> to minimize some distance measure of the model moments <span class="math notranslate nohighlight">\(m(x|\theta)\)</span> from the data moments <span class="math notranslate nohighlight">\(m(x)\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-genprob">
<span class="eqno">(18.3)<a class="headerlink" href="#equation-eqgmm-gmmest-genprob" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{GMM}=\theta:\quad \min_{\theta}\: ||m(x|\theta) - m(x)||\]</div>
<p>The distance measure <span class="math notranslate nohighlight">\(||m(x|\theta) - m(x)||\)</span> can be any kind of norm. But it is important to recognize that your estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> will be dependent on what distance measure (norm) you choose. The most widely studied and used distance metric in GMM estimation is the <span class="math notranslate nohighlight">\(L^2\)</span> norm or the sum of squared errors in moments. Define the moment error function <span class="math notranslate nohighlight">\(e(x|\theta)\)</span> as the <span class="math notranslate nohighlight">\(R \times 1\)</span> vector of either the percent difference in the vector of model moments from the data moments or the simple difference.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-momerr">
<span class="eqno">(18.4)<a class="headerlink" href="#equation-eqgmm-gmmest-momerr" title="Permalink to this equation">#</a></span>\[    e(x|\theta) \equiv \frac{m(x|\theta) - m(x)}{m(x)} \quad\text{or}\quad e(x|\theta) \equiv m(x|\theta) - m(x)\]</div>
<p>It is important when possible that the error function <span class="math notranslate nohighlight">\(e(x|\theta)\)</span> be a percent deviation of the moments (given that none of the data moments are 0). This puts all the moments in the same units, which helps make sure that no moments receive unintended weighting simply due to their units. This ensures that the problem is scaled properly and does not suffer from ill conditioning. However, percent deviations become computationally problematic when the data moments are zero or close to zero. In that case, you would use a simple difference.</p>
<p>The GMM estimator is the following,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-qdrprob">
<span class="eqno">(18.5)<a class="headerlink" href="#equation-eqgmm-gmmest-qdrprob" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{GMM}=\theta:\quad \min_{\theta}\:e(x|\theta)^T \, W \, e(x|\theta)\]</div>
<p>where <span class="math notranslate nohighlight">\(W\)</span> is an <span class="math notranslate nohighlight">\(R\times R\)</span> weighting matrix in the criterion function. For now, think of this weighting matrix as the identity matrix. But we will show in Section <a class="reference internal" href="#secgmm-wgt"><span class="std std-ref">The weighting matrix (W)</span></a> a more optimal weighting matrix. We call the quadratic form expression <span class="math notranslate nohighlight">\(e(x|\theta)^T \, W \, e(x|\theta)\)</span> the <em>criterion function</em> because it is a strictly positive scalar that is the object of the minimization in the GMM problem in the general statement of the problem <a class="reference internal" href="#equation-eqgmm-gmmest-genprob">(18.3)</a> and in the sum of squared errors version of the problem <a class="reference internal" href="#equation-eqgmm-gmmest-qdrprob">(18.5)</a>. The <span class="math notranslate nohighlight">\(R\times R\)</span> weighting matrix <span class="math notranslate nohighlight">\(W\)</span> in the criterion function allows the econometrician to control how each moment is weighted in the minimization problem. For example, an <span class="math notranslate nohighlight">\(R\times R\)</span> identity matrix for <span class="math notranslate nohighlight">\(W\)</span> would give each moment equal weighting of 1, and the criterion function would be a simply sum of squared percent deviations (errors). Other weighting strategies can be dictated by the nature of the problem or model.</p>
</section>
<section id="the-weighting-matrix-w">
<span id="secgmm-wgt"></span><h2><span class="section-number">18.3. </span>The weighting matrix (W)<a class="headerlink" href="#the-weighting-matrix-w" title="Permalink to this heading">#</a></h2>
<p>In the GMM criterion function in the problem statement <a class="reference internal" href="#equation-eqgmm-gmmest-qdrprob">(18.5)</a>, some moment weighting matrices <span class="math notranslate nohighlight">\(W\)</span> produce precise estimates while others produce poor estimates with large variances. We want to choose the optimal weighting matrix <span class="math notranslate nohighlight">\(W\)</span> with the smallest possible asymptotic variance. This is an efficient optimal GMM estimator. The optimal weighting matrix is the inverse variance covariance matrix of the moments at the optimal parameter values,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-wgt-gen">
<span class="eqno">(18.6)<a class="headerlink" href="#equation-eqgmm-wgt-gen" title="Permalink to this equation">#</a></span>\[    W^{opt} \equiv \Omega^{-1}(x|\hat{\theta}_{GMM})\]</div>
<p>where <span class="math notranslate nohighlight">\(\Omega(x|\theta)\)</span> is the variance covariance matrix of the moment condition errors <span class="math notranslate nohighlight">\(E(x|\theta)\)</span> from each observation in the data (to be defined below). The intuition for using the inverse variance covariance matrix <span class="math notranslate nohighlight">\(\Omega^{-1}\)</span> as the optimal weighting matrix is the following. You want to downweight moments that have a high variance, and you want to weight more heavily the moments that are generated more precisely.</p>
<p>Notice that this definition of the optimal weighting matrix is circular. <span class="math notranslate nohighlight">\(W^{opt}\)</span> is a function of the GMM estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span>, but the optimal weighting matrix is used in the estimation of <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span>. This means that one has to use some kind of iterative fixed point method to find the true optimal weighting matrix <span class="math notranslate nohighlight">\(W^{opt}\)</span>. Below are some examples of weighting matrices to use.</p>
<section id="the-identity-matrix-w-i">
<span id="secgmm-wgt-i"></span><h3><span class="section-number">18.3.1. </span>The identity matrix (W=I)<a class="headerlink" href="#the-identity-matrix-w-i" title="Permalink to this heading">#</a></h3>
<p>Many times, you can get away with just using the identity matrix as your weighting matrix <span class="math notranslate nohighlight">\(W = I\)</span>. This changes the criterion function to a simple sum of squared error functions such that each moment has the same weight.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-wi">
<span class="eqno">(18.7)<a class="headerlink" href="#equation-eqgmm-gmmest-wi" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{GMM}=\theta:\quad \min_{\theta}\:e(x|\theta)^T \, e(x|\theta)\]</div>
<p>If the problem is well conditioned and well identified, then your GMM estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> will not be greatly affected by this simplest of weighting matrices.</p>
</section>
<section id="two-step-variance-covariance-estimator-of-w">
<span id="secgmm-wgt-2step"></span><h3><span class="section-number">18.3.2. </span>Two-step variance-covariance estimator of W<a class="headerlink" href="#two-step-variance-covariance-estimator-of-w" title="Permalink to this heading">#</a></h3>
<p>The most common method of estimating the optimal weighting matrix for GMM estimates is the two-step variance covariance estimator. The name “two-step” refers to the two steps used to get the weighting matrix.</p>
<p>The first step is to estimate the GMM parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{1,GMM}\)</span> using the simple identity matrix as the weighting matrix <span class="math notranslate nohighlight">\(W = I\)</span> as in <a class="reference internal" href="#equation-eqgmm-gmmest-wi">(18.7)</a>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-2stp-1">
<span class="eqno">(18.8)<a class="headerlink" href="#equation-eqgmm-gmmest-2stp-1" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{1, GMM}=\theta:\quad \min_{\theta}\:e(x|\theta)^T \, I \, e(x|\theta)\]</div>
<p>As we will show in <a class="reference internal" href="#equation-eqgmm-estw-2step">(18.13)</a>, the optimal two-step weighting matrix is the inverse of the variance-covariance matrix of the moment error vector <span class="math notranslate nohighlight">\(e(x|\theta)\)</span>. To get an estimate of the variance-covariance matrix of the error moment vector, we need a matrix of errors that represents how the calculation of each moment varies across the <span class="math notranslate nohighlight">\(N\)</span> observations in the data.</p>
<p>Define <span class="math notranslate nohighlight">\(E(x|\theta)\)</span> as the <span class="math notranslate nohighlight">\(R\times N\)</span> moment error matrix such that the average across each row gives the moment error vector. When the errors are simple differences, the <span class="math notranslate nohighlight">\(E(x|\theta)\)</span> matrix is the following,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-2stp-errmatsimp">
<span class="eqno">(18.9)<a class="headerlink" href="#equation-eqgmm-gmmest-2stp-errmatsimp" title="Permalink to this equation">#</a></span>\[\begin{split}    E(x|\theta) =
    \begin{bmatrix}
        m_1(x|\theta) - m_1(x_1) &amp; m_1(x|\theta) - m_1(x_2) &amp; ... &amp; m_1(x|\theta) - m_1(x_N) \\
        m_2(x|\theta) - m_2(x_1) &amp; m_2(x|\theta) - m_2(x_2) &amp; ... &amp; m_2(x|\theta) - m_2(x_N) \\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
        m_R(x|\theta) - m_R(x_1) &amp; m_R(x|\theta) - m_R(x_2) &amp; ... &amp; m_R(x|\theta) - m_R(x_N) \\
    \end{bmatrix}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(m_r(x_i)\)</span> is a function associated with the <span class="math notranslate nohighlight">\(r\)</span>th moment and the <span class="math notranslate nohighlight">\(i\)</span>th data observation. When the errors are percent deviations, the <span class="math notranslate nohighlight">\(E(x|\theta)\)</span> matrix is the following,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-2stp-errmatpct">
<span class="eqno">(18.10)<a class="headerlink" href="#equation-eqgmm-gmmest-2stp-errmatpct" title="Permalink to this equation">#</a></span>\[\begin{split}    E(x|\theta) =
    \begin{bmatrix}
        \frac{m_1(x|\theta) - m_1(x_1)}{m_1(x_1)} &amp; \frac{m_1(x|\theta) - m_1(x_2)}{m_1(x_2)} &amp; ... &amp; \frac{m_1(x|\theta) - m_1(x_N)}{m_1(x_N)} \\
        \frac{m_2(x|\theta) - m_2(x_1)}{m_2(x_1)} &amp; \frac{m_2(x|\theta) - m_2(x_2)}{m_2(x_2)} &amp; ... &amp; \frac{m_2(x|\theta) - m_2(x_N)}{m_2(x_N)} \\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
        \frac{m_R(x|\theta) - m_R(x_1)}{m_R(x_1)} &amp; \frac{m_R(x|\theta) - m_R(x_2)}{m_R(x_2)} &amp; ... &amp; \frac{m_R(x|\theta) - m_R(x_N)}{m_R(x_N)} \\
    \end{bmatrix}\end{split}\]</div>
<p>where the denominator of the percentage deviation or baseline is the model moment that does not change. We use the <span class="math notranslate nohighlight">\(E(x|\theta)\)</span> data matrix and the Step 1 GMM estimate <span class="math notranslate nohighlight">\(e(x|\hat{\theta}_{1,GMM})\)</span> to get a new estimate of the variance covariance matrix.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-gmmest-2stp-2varcov">
<span class="eqno">(18.11)<a class="headerlink" href="#equation-eqgmm-gmmest-2stp-2varcov" title="Permalink to this equation">#</a></span>\[    \hat{\Omega}_2 = \frac{1}{N}E(x|\hat{\theta}_{1,GMM})\,E(x|\hat{\theta}_{1,GMM})^T\]</div>
<p>This is simply saying that the <span class="math notranslate nohighlight">\((r,s)\)</span>-element of the <span class="math notranslate nohighlight">\(R\times R\)</span> estimator of the variance-covariance matrix of the moment vector is the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-2stepvarcov-rs">
<span class="eqno">(18.12)<a class="headerlink" href="#equation-eqgmm-2stepvarcov-rs" title="Permalink to this equation">#</a></span>\[    \hat{\Omega}_{2,r,s} = \frac{1}{N}\sum_{i=1}^N\Bigl[m_r(x|\theta) - m_{r}(x_i)\Bigr]\Bigl[m_s(x|\theta) - m_s(x_i)\Bigr]\]</div>
<p>The optimal weighting matrix is the inverse of the two-step variance covariance matrix.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-estw-2step">
<span class="eqno">(18.13)<a class="headerlink" href="#equation-eqgmm-estw-2step" title="Permalink to this equation">#</a></span>\[    \hat{W}^{two-step} \equiv \hat{\Omega}_2^{-1}\]</div>
<p>Lastly, re-estimate the GMM estimator using the optimal two-step weighting matrix <span class="math notranslate nohighlight">\(\hat{W}^{2step}\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-theta-2step-2">
<span class="eqno">(18.14)<a class="headerlink" href="#equation-eqgmm-theta-2step-2" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{2,GMM}=\theta:\quad \min_{\theta}\:e(x|\theta)^T \, \hat{W}^{two-step} \, e(x|\theta)\]</div>
<p><span class="math notranslate nohighlight">\(\hat{\theta}_{2,GMM}\)</span> is called the two-step GMM estimator.</p>
</section>
<section id="iterated-variance-covariance-estimator-of-w">
<span id="secgmm-w-iter"></span><h3><span class="section-number">18.3.3. </span>Iterated variance-covariance estimator of W<a class="headerlink" href="#iterated-variance-covariance-estimator-of-w" title="Permalink to this heading">#</a></h3>
<p>The truly optimal weighting matrix <span class="math notranslate nohighlight">\(W^{opt}\)</span> is the iterated variance-covariance estimator of <span class="math notranslate nohighlight">\(W\)</span>. This procedure is to just repeat the process described in the two-step GMM estimator until the estimated weighting matrix no longer significantly changes between iterations. Let <span class="math notranslate nohighlight">\(i\)</span> index the <span class="math notranslate nohighlight">\(i\)</span>th iterated GMM estimator,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-theta-2step-i">
<span class="eqno">(18.15)<a class="headerlink" href="#equation-eqgmm-theta-2step-i" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{i, GMM}=\theta:\quad \min_{\theta}\:e(x|\theta)^T \, \hat{W}_{i} \, e(x|\theta)\]</div>
<p>and the <span class="math notranslate nohighlight">\((i+1)\)</span>th estimate of the optimal weighting matrix is defined as the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-estw-istep">
<span class="eqno">(18.16)<a class="headerlink" href="#equation-eqgmm-estw-istep" title="Permalink to this equation">#</a></span>\[    \hat{W}_{i+1} \equiv \hat{\Omega}_{i+1}^{-1}\quad\text{where}\quad \hat{\Omega}_{i+1} = \frac{1}{N}E(x|\hat{\theta}_{i,GMM})\,E(x|\hat{\theta}_{i,GMM})^T\]</div>
<p>The iterated GMM estimator <span class="math notranslate nohighlight">\(\hat{\theta}_{it,GMM}\)</span> is the <span class="math notranslate nohighlight">\(\hat{\theta}_{i,GMM}\)</span> such that <span class="math notranslate nohighlight">\(\hat{W}_{i+1}\)</span> is very close to <span class="math notranslate nohighlight">\(\hat{W}_{i}\)</span> for some distance metric (norm).</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-theta-it">
<span class="eqno">(18.17)<a class="headerlink" href="#equation-eqgmm-theta-it" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{it,GMM} = \hat{\theta}_{i,GMM}: \quad || \hat{W}_{i+1} - \hat{W}_{i} || &lt; \varepsilon\]</div>
</section>
<section id="newey-west-consistent-estimator-of-omega-and-w">
<span id="secgmm-w-nw"></span><h3><span class="section-number">18.3.4. </span>Newey-West consistent estimator of <span class="math notranslate nohighlight">\(\Omega\)</span> and W<a class="headerlink" href="#newey-west-consistent-estimator-of-omega-and-w" title="Permalink to this heading">#</a></h3>
<p>The Newey-West estimator of the optimal weighting matrix and variance covariance matrix is consistent in the presence of heteroskedasticity and autocorrelation in the data (See <span id="id6">[<a class="reference internal" href="../CompMethods_references.html#id50" title="Whitney K. Newey and Kenneth D. West. A simple, positive, semi-definite, heteroskedasticy and autocorrelation consistent covariance matrix. Econometrica, 55(3):703-708, May 1987.">Newey and West, 1987</a>]</span>). <span id="id7">[<a class="reference internal" href="../CompMethods_references.html#id2" title="Jérôme Adda and Russell Cooper. Dynamic Economics: Quantitative Methods and Applications. MIT Press, 2003.">Adda and Cooper, 2003</a>]</span> (p. 82) have a nice exposition of how to compute the Newey-West weighting matrix <span class="math notranslate nohighlight">\(\hat{W}_{nw}\)</span>. The asymptotic representation of the optimal weighting matrix <span class="math notranslate nohighlight">\(\hat{W}^{opt}\)</span> is the following:</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-estw-whatopt">
<span class="eqno">(18.18)<a class="headerlink" href="#equation-eqgmm-estw-whatopt" title="Permalink to this equation">#</a></span>\[    \hat{W}^{opt} = \lim_{N\rightarrow\infty}\frac{1}{N}\sum_{i=1}^N \sum_{l=-\infty}^\infty E(x_i|\theta)E(x_{i-l}|\theta)^T\]</div>
<p>The Newey-West consistent estimator of <span class="math notranslate nohighlight">\(\hat{W}^{opt}\)</span> is:</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-estw-nw">
<span class="eqno">(18.19)<a class="headerlink" href="#equation-eqgmm-estw-nw" title="Permalink to this equation">#</a></span>\[    \hat{W}_{nw} = \Gamma_{0,N} + \sum_{v=1}^q \left(1 - \left[\frac{v}{q+1}\right]\right)\left(\Gamma_{v,N} + \Gamma^T_{v,N}\right)\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-estw-nwgamma">
<span class="eqno">(18.20)<a class="headerlink" href="#equation-eqgmm-estw-nwgamma" title="Permalink to this equation">#</a></span>\[    \Gamma_{v,N} = \frac{1}{N}\sum_{i=v+1}^N E(x_i|\theta)E(x_{i-v}|\theta)^T\]</div>
<p>Of course, for autocorrelation, the subscript <span class="math notranslate nohighlight">\(i\)</span> can be changed to <span class="math notranslate nohighlight">\(t\)</span>.</p>
</section>
</section>
<section id="variance-covariance-estimator-of-hat-theta">
<span id="secgmm-varcovtheta"></span><h2><span class="section-number">18.4. </span>Variance-Covariance Estimator of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span><a class="headerlink" href="#variance-covariance-estimator-of-hat-theta" title="Permalink to this heading">#</a></h2>
<p>The estimated variance-covariance matrix <span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span> of the estimated parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> is different from the variance-covariance matrix <span class="math notranslate nohighlight">\(\hat{\Omega}\)</span> of the moment vector <span class="math notranslate nohighlight">\(e(x|\theta)\)</span> from the previous section. <span class="math notranslate nohighlight">\(\hat{\Omega}\)</span> from the previous section is the <span class="math notranslate nohighlight">\(R\times R\)</span> variance-covariance matrix of the <span class="math notranslate nohighlight">\(R\)</span> moment errors used to identify the <span class="math notranslate nohighlight">\(K\)</span> parameters <span class="math notranslate nohighlight">\(\theta\)</span> to be estimated. The estimated variance-covariance matrix of the estimated parameter vector <span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span> is a <span class="math notranslate nohighlight">\(K\times K\)</span> matrix. We say the model is exactly identified if <span class="math notranslate nohighlight">\(K = R\)</span>. We say the model is overidentified if <span class="math notranslate nohighlight">\(K&lt;R\)</span>.</p>
<p>Similar to the inverse Hessian estimator of the variance-covariance matrix of the maximum likelihood estimator from the <a class="reference internal" href="MLE.html#chap-mle"><span class="std std-ref">Maximum Likelihood Estimation</span></a>, the GMM variance-covariance matrix is related to the derivative of the criterion function with respect to each parameter. The intuition is that if the second derivative of the criterion function with respect to the parameters is large, there is a lot of curvature around the criterion minimizing estimate. In other words, the parameters of the model are precisely estimated. The inverse of the Hessian matrix will be small.</p>
<p>Define <span class="math notranslate nohighlight">\(R\times K\)</span> matrix <span class="math notranslate nohighlight">\(d(x|\theta)\)</span> as the Jacobian matrix of derivatives of the <span class="math notranslate nohighlight">\(R\times 1\)</span> error vector <span class="math notranslate nohighlight">\(e(x|\theta)\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-errvec-deriv">
<span class="eqno">(18.21)<a class="headerlink" href="#equation-eqgmm-errvec-deriv" title="Permalink to this equation">#</a></span>\[\begin{split}    \begin{equation}
    d(x|\theta) \equiv
        \begin{bmatrix}
        \frac{\partial e_1(x|\theta)}{\partial \theta_1} &amp; \frac{\partial e_1(x|\theta)}{\partial \theta_2} &amp; ... &amp; \frac{\partial e_1(x|\theta)}{\partial \theta_K} \\
        \frac{\partial e_2(x|\theta)}{\partial \theta_1} &amp; \frac{\partial e_2(x|\theta)}{\partial \theta_2} &amp; ... &amp; \frac{\partial e_2(x|\theta)}{\partial \theta_K} \\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
        \frac{\partial e_R(x|\theta)}{\partial \theta_1} &amp; \frac{\partial e_R(x|\theta)}{\partial \theta_2} &amp; ... &amp; \frac{\partial e_R(x|\theta)}{\partial \theta_K}
        \end{bmatrix}
    \end{equation}\end{split}\]</div>
<p>The GMM estimates of the parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> are assymptotically normal. If <span class="math notranslate nohighlight">\(\theta_0\)</span> is the true value of the parameters, then the following holds,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-theta-plim">
<span class="eqno">(18.22)<a class="headerlink" href="#equation-eqgmm-theta-plim" title="Permalink to this equation">#</a></span>\[    \text{plim}_{N\rightarrow\infty}\sqrt{N}\left(\hat{\theta}_{GMM} - \theta_0\right) \sim \text{N}\left(0, \left[d(x|\theta)^T W d(x|\theta)\right]^{-1}\right)\]</div>
<p>where <span class="math notranslate nohighlight">\(W\)</span> is the optimal weighting matrix from the GMM criterion function. The GMM estimator for the variance-covariance matrix <span class="math notranslate nohighlight">\(\hat{\Sigma}_{GMM}\)</span> of the parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> is the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-sigmahat">
<span class="eqno">(18.23)<a class="headerlink" href="#equation-eqgmm-sigmahat" title="Permalink to this equation">#</a></span>\[    \hat{\Sigma}_{GMM} = \frac{1}{N}\left[d(x|\theta)^T W d(x|\theta)\right]^{-1}\]</div>
<p>In the examples below, we will use a finite difference method to compute numerical versions of the Jacobian matrix <span class="math notranslate nohighlight">\(d(\tilde{x},x|\theta)\)</span>. The following is a first-order forward finite difference numerical approximation of the first derivative of a function.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-finitediff-1">
<span class="eqno">(18.24)<a class="headerlink" href="#equation-eqgmm-finitediff-1" title="Permalink to this equation">#</a></span>\[    f'(x_0) = \lim_{h\rightarrow 0} \frac{f(x_0 + h) - f(x_0)}{h}\]</div>
<p>The following is a centered second-order finite difference numerical approximation of the derivative of a function. (See <a class="reference external" href="https://github.com/UC-MACSS/persp-model-econ_W19/blob/master/Notes/ACME_NumDiff.pdf">BYU ACME numerical differentiation lab</a> for more details.)</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-finitediff-2">
<span class="eqno">(18.25)<a class="headerlink" href="#equation-eqgmm-finitediff-2" title="Permalink to this equation">#</a></span>\[    f'(x_0) \approx \frac{f(x_0 + h) - f(x_0 - h)}{2h}\]</div>
</section>
<section id="code-examples">
<span id="secgmm-ex"></span><h2><span class="section-number">18.5. </span>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this heading">#</a></h2>
<p>In this section, we will use GMM to estimate parameters of the models from the <a class="reference internal" href="MLE.html#chap-mle"><span class="std std-ref">Maximum Likelihood Estimation</span></a> chapter. We will also go through the standard moment conditions in most econometrics textbooks in which the conditional and unconditional expectations provide moments for estimation.</p>
<section id="fitting-a-truncated-normal-to-intermediate-macroeconomics-test-scores">
<span id="secgmm-ex-trunc"></span><h3><span class="section-number">18.5.1. </span>Fitting a truncated normal to intermediate macroeconomics test scores<a class="headerlink" href="#fitting-a-truncated-normal-to-intermediate-macroeconomics-test-scores" title="Permalink to this heading">#</a></h3>
<p>Let’s revisit the problem from the <a class="reference internal" href="MLE.html#chap-mle"><span class="std std-ref">Maximum Likelihood Estimation</span></a> chapter of fitting a truncated normal distribution to intermediate macroeconomics test scores. The data are in the text file <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/data/gmm/Econ381totpts.txt"><code class="docutils literal notranslate"><span class="pre">Econ381totpts.txt</span></code></a> in the GitHub repository <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/tree/main/data/gmm"><code class="docutils literal notranslate"><span class="pre">../data/gmm/</span></code></a> folder for this executable book. Recall that these test scores are between 0 and 450. <a class="reference internal" href="#figgmm-econscores2mles"><span class="std std-numref">Figure 18.1</span></a> below shows a histogram of the data, as well as the unconstrained and constrained maximum likelihood estimates of the truncated normal distribution from <a class="reference internal" href="MLE.html#figmle-econscoresmleconstr"><span class="std std-numref">Figure 17.6</span></a> as well as an arbitrary distribution.</p>
<p>The black line is the unconstrained MLE estimate of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> of the truncated normal pdf from Section <a class="reference internal" href="MLE.html#secmle-distdata-min"><span class="std std-ref">The minimize() function</span></a>. The red line is the constrained MLE estimate of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> from Section <a class="reference internal" href="MLE.html#secmle-distdata-conmin"><span class="std std-ref">Constrained minimization</span></a>. And the green line is an arbitrary parameterization of the truncated normal PDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">sts</span>


<span class="k">def</span> <span class="nf">trunc_norm_pdf</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cut_ub</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    Generate pdf values from the truncated normal pdf with mean mu and</span>
<span class="sd">    standard deviation sigma. If the cutoff is given, then the PDF</span>
<span class="sd">    values are inflated upward to reflect the zero probability on values</span>
<span class="sd">    above the cutoff. If there is no cutoff given, this function does</span>
<span class="sd">    the same thing as sp.stats.norm.pdf(x, loc=mu, scale=sigma).</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals  = (N,) vector, values of the normally distributed random</span>
<span class="sd">             variable</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION: None</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    prob_notcut = scalar</span>
<span class="sd">    pdf_vals = (N,) vector, normal PDF values for mu and sigma</span>
<span class="sd">               corresponding to xvals data</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: pdf_vals</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">cut_ub</span> <span class="o">==</span> <span class="s1">&#39;None&#39;</span> <span class="ow">and</span> <span class="n">cut_lb</span> <span class="o">==</span> <span class="s1">&#39;None&#39;</span><span class="p">:</span>
        <span class="n">prob_notcut</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">elif</span> <span class="n">cut_ub</span> <span class="o">==</span> <span class="s1">&#39;None&#39;</span> <span class="ow">and</span> <span class="n">cut_lb</span> <span class="o">!=</span> <span class="s1">&#39;None&#39;</span><span class="p">:</span>
        <span class="n">prob_notcut</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">sts</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">cut_lb</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cut_ub</span> <span class="o">!=</span> <span class="s1">&#39;None&#39;</span> <span class="ow">and</span> <span class="n">cut_lb</span> <span class="o">==</span> <span class="s1">&#39;None&#39;</span><span class="p">:</span>
        <span class="n">prob_notcut</span> <span class="o">=</span> <span class="n">sts</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">cut_ub</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cut_ub</span> <span class="o">!=</span> <span class="s1">&#39;None&#39;</span> <span class="ow">and</span> <span class="n">cut_lb</span> <span class="o">!=</span> <span class="s1">&#39;None&#39;</span><span class="p">:</span>
        <span class="n">prob_notcut</span> <span class="o">=</span> <span class="p">(</span><span class="n">sts</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">cut_ub</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="o">-</span>
                       <span class="n">sts</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">cut_lb</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>

    <span class="n">pdf_vals</span>    <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span> <span class="o">*</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span> <span class="o">/</span>
                    <span class="n">prob_notcut</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pdf_vals</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the necessary libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="c1"># Download and save the data file Econ381totpts.txt as NumPy array</span>
<span class="n">url</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/OpenSourceEcon/CompMethods/&#39;</span> <span class="o">+</span>
       <span class="s1">&#39;main/data/gmm/Econ381totpts.txt&#39;</span><span class="p">)</span>
<span class="n">data_file</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../../../data/gmm/Econ381totpts.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data_file</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="k">if</span> <span class="n">data_file</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="c1"># Load the downloaded data into a NumPy array</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;../../../data/gmm/Econ381totpts.txt&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error downloading the file&#39;</span><span class="p">)</span>

<span class="c1"># Plot the histogram of the data</span>
<span class="n">num_bins</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Intermediate macro scores: 2011-2012&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Total points&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Percent of scores&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">550</span><span class="p">])</span>  <span class="c1"># This gives the xmin and xmax to be plotted&quot;</span>

<span class="c1"># Plot the unconstrained MLE estimated distribution</span>
<span class="n">dist_pts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">450</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">mu_MLE</span> <span class="o">=</span> <span class="mf">622.16</span>
<span class="n">sig_MLE</span> <span class="o">=</span> <span class="mf">198.76</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">dist_pts</span><span class="p">,</span>
    <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">dist_pts</span><span class="p">,</span> <span class="n">mu_MLE</span><span class="p">,</span> <span class="n">sig_MLE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Unconstr: $\hat{\mu}_</span><span class="si">{MLE}</span><span class="s1">$=622,$\hat{\sigma}_</span><span class="si">{MLE}</span><span class="s1">$=199&#39;</span>
<span class="p">)</span>

<span class="c1"># Plot the constrained MLE estimated distribution</span>
<span class="n">mu_MLE_constr</span> <span class="o">=</span> <span class="mf">420.0</span>
<span class="n">sig_MLE_constr</span> <span class="o">=</span> <span class="mf">129.04</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">dist_pts</span><span class="p">,</span>
    <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">dist_pts</span><span class="p">,</span> <span class="n">mu_MLE_constr</span><span class="p">,</span> <span class="n">sig_MLE_constr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Constr: $\hat{\mu}_</span><span class="si">{MLE}</span><span class="s1">$=420,$\hat{\sigma}_</span><span class="si">{MLE}</span><span class="s1">$=129&#39;</span>
<span class="p">)</span>

<span class="c1"># Plot smooth line with distribution 1</span>
<span class="n">mu_1</span> <span class="o">=</span> <span class="mi">380</span>
<span class="n">sig_1</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dist_pts</span><span class="p">,</span> <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">dist_pts</span><span class="p">,</span> <span class="n">mu_1</span><span class="p">,</span> <span class="n">sig_1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Arbitrary: $\mu$=380,$\sigma$=150&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<figure class="align-default" id="figgmm-econscores2mles">
<a class="reference internal image-reference" href="../_images/Econ381scores_2MLEs.png"><img alt="../_images/Econ381scores_2MLEs.png" src="../_images/Econ381scores_2MLEs.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18.1 </span><span class="caption-text">Constrained maximum likelihood estimate of truncated normal distribution to fit intermediate macroeconomics midterm scores over two semesters along with unconstrained MLE estimate and arbitrary parameterization.</span><a class="headerlink" href="#figgmm-econscores2mles" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="two-moments-identity-weighting-matrix">
<span id="secgmm-ex-trunc-2momi"></span><h4><span class="section-number">18.5.1.1. </span>Two moments, identity weighting matrix<a class="headerlink" href="#two-moments-identity-weighting-matrix" title="Permalink to this heading">#</a></h4>
<p>Let’s try estimating the parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> by GMM. What moments should we use? Let’s try the mean and variance of the data. These two statistics of the data are defined by:</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-trunc-2momi-mean">
<span class="eqno">(18.26)<a class="headerlink" href="#equation-eqgmm-ex-trunc-2momi-mean" title="Permalink to this equation">#</a></span>\[    mean(scores_i) = \frac{1}{N}\sum_{i=1}^N scores_i\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-trunc-2momi-var">
<span class="eqno">(18.27)<a class="headerlink" href="#equation-eqgmm-ex-trunc-2momi-var" title="Permalink to this equation">#</a></span>\[    var(scores_i) = \frac{1}{N}\sum_{i=1}^{N} \left(scores_i - mean(scores_i)\right)^2\]</div>
<p>So the data moment vector <span class="math notranslate nohighlight">\(m(x)\)</span> for GMM is the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-trunc-2momi-datamoms">
<span class="eqno">(18.28)<a class="headerlink" href="#equation-eqgmm-ex-trunc-2momi-datamoms" title="Permalink to this equation">#</a></span>\[\begin{split}    m(scores_i) \equiv \begin{bmatrix} mean(scores_i) \\ var(scores_i) \end{bmatrix}\end{split}\]</div>
<p>And the model moment vector <span class="math notranslate nohighlight">\(m(x|\theta)\)</span> for GMM is the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-trunc-2momi-modmoms">
<span class="eqno">(18.29)<a class="headerlink" href="#equation-eqgmm-ex-trunc-2momi-modmoms" title="Permalink to this equation">#</a></span>\[\begin{split}    m(scores_i|\mu,\sigma) \equiv \begin{bmatrix} mean(scores_i|\mu,\sigma) \\ var(scores_i|\mu,\sigma) \end{bmatrix}\end{split}\]</div>
<p>Define the error vector as the vector of percent deviations of the model moments from the data moments.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-trunc-2momi-errvec">
<span class="eqno">(18.30)<a class="headerlink" href="#equation-eqgmm-ex-trunc-2momi-errvec" title="Permalink to this equation">#</a></span>\[    e(scores_i|\mu,\sigma) \equiv \frac{m(scores_i|\mu,\sigma) - m(scores_i)}{m(scores_i)}\]</div>
<p>The mimization problem for the GMM estimator for this moment vector is the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-trunc-2momi-minprob">
<span class="eqno">(18.31)<a class="headerlink" href="#equation-eqgmm-ex-trunc-2momi-minprob" title="Permalink to this equation">#</a></span>\[    (\hat{\mu}_{GMM},\hat{\sigma}_{GMM}) = (\mu,\sigma):\quad \min_{\mu,\sigma} e(scores_i|\mu,\sigma)^T \, W \, e(scores_i|\mu,\sigma)\]</div>
<p>Keep in mind that the <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> we are estimating are the two truncated normal parameters in contrast to the empirical mean of the data <span class="math notranslate nohighlight">\(mean(scores_i)\)</span> and the empirical variance of the data <span class="math notranslate nohighlight">\(var(scores_i)\)</span>.</p>
<p>Something interesting to note here is the <span class="math notranslate nohighlight">\(1/N\)</span> weighting on our variance estimator. There is less bias in the estimator of the variance by using the weighting <span class="math notranslate nohighlight">\(1/(N-1)\)</span> because one degree of freedom is used in calculating the mean used in the variance calculation. However, in GMM when many moments are used that might have differing degrees of freedom restrictions, it is important to have the same weighting for each moment. So we use <span class="math notranslate nohighlight">\(1/N\)</span> in all cases.</p>
<p>Now let’s define a criterion function that takes as inputs the parameters and the estimator for the weighting matrix <span class="math notranslate nohighlight">\(\hat{W}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.integrate</span> <span class="k">as</span> <span class="nn">intgr</span>

<span class="k">def</span> <span class="nf">data_moments</span><span class="p">(</span><span class="n">xvals</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the two data moments for GMM</span>
<span class="sd">    (mean(data), variance(data)).</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals = (N,) vector, test scores data</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION: None</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    mean_data = scalar, mean value of test scores data</span>
<span class="sd">    var_data  = scalar &gt; 0, variance of test scores data</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: mean_data, var_data</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">mean_data</span> <span class="o">=</span> <span class="n">xvals</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">var_data</span> <span class="o">=</span> <span class="n">xvals</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">mean_data</span><span class="p">,</span> <span class="n">var_data</span>


<span class="k">def</span> <span class="nf">model_moments</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the two model moments for GMM</span>
<span class="sd">    (mean(model data), variance(model data)).</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        trunc_norm_pdf()</span>
<span class="sd">        xfx()</span>
<span class="sd">        x2fx()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    mean_model = scalar, mean value of test scores from model</span>
<span class="sd">    m_m_err    = scalar &gt; 0, estimated error in the computation of the</span>
<span class="sd">                 integral for the mean of the distribution</span>
<span class="sd">    var_model  = scalar &gt; 0, variance of test scores from model</span>
<span class="sd">    v_m_err    = scalar &gt; 0, estimated error in the computation of the</span>
<span class="sd">                 integral for the variance of the distribution</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: mean_model, var_model</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">xfx</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="p">(</span><span class="n">mean_model</span><span class="p">,</span> <span class="n">m_m_err</span><span class="p">)</span> <span class="o">=</span> <span class="n">intgr</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">xfx</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="n">x2fx</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean_model</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="p">(</span><span class="n">var_model</span><span class="p">,</span> <span class="n">v_m_err</span><span class="p">)</span> <span class="o">=</span> <span class="n">intgr</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">x2fx</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mean_model</span><span class="p">,</span> <span class="n">var_model</span>


<span class="k">def</span> <span class="nf">err_vec</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the vector of moment errors (in percent</span>
<span class="sd">    deviation from the data moment vector) for GMM.</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals  = (N,) vector, test scores data</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    simple = boolean, =True if errors are simple difference, =False if</span>
<span class="sd">             errors are percent deviation from data moments</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        data_moments()</span>
<span class="sd">        model_moments()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    mean_data  = scalar, mean value of data</span>
<span class="sd">    var_data   = scalar &gt; 0, variance of data</span>
<span class="sd">    moms_data  = (2, 1) matrix, column vector of two data moments</span>
<span class="sd">    mean_model = scalar, mean value from model</span>
<span class="sd">    var_model  = scalar &gt; 0, variance from model</span>
<span class="sd">    moms_model = (2, 1) matrix, column vector of two model moments</span>
<span class="sd">    err_vec    = (2, 1) matrix, column vector of two moment error</span>
<span class="sd">                 functions</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: err_vec</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">mean_data</span><span class="p">,</span> <span class="n">var_data</span> <span class="o">=</span> <span class="n">data_moments</span><span class="p">(</span><span class="n">xvals</span><span class="p">)</span>
    <span class="n">moms_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">mean_data</span><span class="p">],</span> <span class="p">[</span><span class="n">var_data</span><span class="p">]])</span>
    <span class="n">mean_model</span><span class="p">,</span> <span class="n">var_model</span> <span class="o">=</span> <span class="n">model_moments</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="n">moms_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">mean_model</span><span class="p">],</span> <span class="p">[</span><span class="n">var_model</span><span class="p">]])</span>
    <span class="k">if</span> <span class="n">simple</span><span class="p">:</span>
        <span class="n">err_vec</span> <span class="o">=</span> <span class="n">moms_model</span> <span class="o">-</span> <span class="n">moms_data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">err_vec</span> <span class="o">=</span> <span class="p">(</span><span class="n">moms_model</span> <span class="o">-</span> <span class="n">moms_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">moms_data</span>

    <span class="k">return</span> <span class="n">err_vec</span>


<span class="k">def</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the GMM weighted sum of squared moment errors</span>
<span class="sd">    criterion function value given parameter values and an estimate of</span>
<span class="sd">    the weighting matrix.</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    params = (2,) vector, ([mu, sigma])</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    args   = length 3 tuple, (xvals, cutoff, W_hat)</span>
<span class="sd">    xvals  = (N,) vector, values of the truncated normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    W_hat  = (R, R) matrix, estimate of optimal weighting matrix</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        norm_pdf()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    err        = (2, 1) matrix, column vector of two moment error</span>
<span class="sd">                 functions</span>
<span class="sd">    crit_val   = scalar &gt; 0, GMM criterion function value</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: crit_val</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">xvals</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">args</span>
    <span class="n">err</span> <span class="o">=</span> <span class="n">err_vec</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">crit_val</span> <span class="o">=</span> <span class="n">err</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W</span> <span class="o">@</span> <span class="n">err</span>

    <span class="k">return</span> <span class="n">crit_val</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can perform the GMM estimation. Let’s start with the identity matrix as our estimate for the optimal weighting matrix <span class="math notranslate nohighlight">\(W = I\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="k">as</span> <span class="nn">opt</span>

<span class="c1"># Note that this takes a little time because the intgr.quad() commands</span>
<span class="c1"># are a little slow</span>
<span class="n">mu_init</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">sig_init</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">params_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_init</span><span class="p">,</span> <span class="n">sig_init</span><span class="p">])</span>
<span class="n">W_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">gmm_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">params_init</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">gmm_args</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">params_init</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">gmm_args</span><span class="p">),</span>
                       <span class="n">tol</span><span class="o">=</span><span class="mf">1e-14</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span>
                       <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
<span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu_GMM1=&#39;</span><span class="p">,</span> <span class="n">mu_GMM1</span><span class="p">,</span> <span class="s1">&#39; sig_GMM1=&#39;</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SciPy.optimize.minimize results are the following:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mu_GMM1= 622.0452991337212  sig_GMM1= 198.72061665917036

SciPy.optimize.minimize results are the following:
  message: CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH
  success: True
   status: 0
      fun: 2.6188955144709652e-18
        x: [ 6.220e+02  1.987e+02]
      nit: 19
      jac: [-2.986e-13  1.192e-12]
     nfev: 87
     njev: 29
 hess_inv: &lt;2x2 LbfgsInvHessProduct with dtype=float64&gt;
</pre></div>
</div>
</div>
</div>
<p>The data moments, model moments at the optimal parameters, and error vector values are the following.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_data</span><span class="p">,</span> <span class="n">var_data</span> <span class="o">=</span> <span class="n">data_moments</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">mean_model</span><span class="p">,</span> <span class="n">var_model</span> <span class="o">=</span> <span class="n">model_moments</span><span class="p">(</span><span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">)</span>
<span class="n">err1</span> <span class="o">=</span> <span class="n">err_vec</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean of points =&#39;</span><span class="p">,</span> <span class="n">mean_data</span><span class="p">,</span> <span class="s1">&#39;, Variance of points =&#39;</span><span class="p">,</span> <span class="n">var_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean of model =&#39;</span><span class="p">,</span> <span class="n">mean_model</span><span class="p">,</span> <span class="s1">&#39;, Variance of model =&#39;</span><span class="p">,</span> <span class="n">var_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Error vector=&#39;</span><span class="p">,</span> <span class="n">err1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean of points = 341.90869565217395 , Variance of points = 7827.997292398056
Mean of model = 341.9086951086106 , Variance of model = 7827.997290030685
Error vector= [-1.58979102e-09 -3.02423591e-10]
</pre></div>
</div>
</div>
</div>
<p>As we can see from the criterion function value at the optimum (2.69e-18) and from the difference between the model moments and data moments, this GMM estimation matches the moments very well. This GMM estimation is also very close to the unconstrained MLE estimates from Section <a class="reference internal" href="MLE.html#secmle-distdata-min"><span class="std std-ref">The minimize() function</span></a>.</p>
<p><a class="reference internal" href="#figgmm-surfcrit1"><span class="std std-numref">Figure 18.2</span></a> shows the criterion function surface for different values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> in the neighborhood of our GMM estimate.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">cmap1</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">colormaps</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;summer&#39;</span><span class="p">)</span>

<span class="n">critfunc_GMM1</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">]),</span>
                          <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat</span><span class="p">)</span>

<span class="n">mu_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">590</span><span class="p">,</span> <span class="mi">650</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
<span class="n">sig_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">220</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">critfunc_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="k">for</span> <span class="n">mu_ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">90</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">sig_ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">critfunc_vals</span><span class="p">[</span><span class="n">mu_ind</span><span class="p">,</span> <span class="n">sig_ind</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">criterion</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_vals</span><span class="p">[</span><span class="n">mu_ind</span><span class="p">],</span> <span class="n">sig_vals</span><span class="p">[</span><span class="n">sig_ind</span><span class="p">]]),</span>
                      <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sig_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">mu_vals</span><span class="p">,</span> <span class="n">sig_vals</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;3d&quot;</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">mu_mesh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">sig_mesh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">critfunc_vals</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="n">critfunc_GMM1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span>
           <span class="n">s</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GMM estimate&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">elev</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">azim</span><span class="o">=-</span><span class="mi">7</span><span class="p">,</span> <span class="n">roll</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Criterion function surface for values of mu and sigma&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\sigma$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Criterion func.&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="figgmm-surfcrit1">
<a class="reference internal image-reference" href="../_images/Econ381scores_SurfaceCrit1.png"><img alt="../_images/Econ381scores_SurfaceCrit1.png" src="../_images/Econ381scores_SurfaceCrit1.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18.2 </span><span class="caption-text">Surface of the 2 moment, identity weighting matrix GMM criterion function for values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> in the neighborhood of the GMM estimate. The scatter point represents the criterion function value for the GMM estimate.</span><a class="headerlink" href="#figgmm-surfcrit1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Let’s compute the GMM estimator for the variance-covariance matrix <span class="math notranslate nohighlight">\(\hat{\Sigma}_{GMM}\)</span> of our GMM estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span> using the equation in Section 4 based on the Jacobian <span class="math notranslate nohighlight">\(d(x|\hat{\theta}_{GMM})\)</span> of the moment error vector <span class="math notranslate nohighlight">\(e(x|\hat{\theta}_{GMM})\)</span> from the criterion function at the estimated (optimal) parameter values <span class="math notranslate nohighlight">\(\hat{\theta}_{GMM}\)</span>. We first write a function that computes the Jacobian <span class="math notranslate nohighlight">\(d(x|\hat{\theta}_{GMM})\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">lin</span>

<span class="k">def</span> <span class="nf">Jac_err2</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function computes the Jacobian matrix of partial derivatives of the</span>
<span class="sd">    R x 1 moment error vector e(x|theta) with respect to the K parameters</span>
<span class="sd">    theta_i in the K x 1 parameter vector theta. The resulting matrix is the</span>
<span class="sd">    R x K Jacobian.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">Jac_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">h_mu</span> <span class="o">=</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">mu</span>
    <span class="n">h_sig</span> <span class="o">=</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">sigma</span>
    <span class="n">Jac_err</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">err_vec</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">h_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">)</span> <span class="o">-</span>
         <span class="n">err_vec</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">h_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">))</span> <span class="o">/</span>
        <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h_mu</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">Jac_err</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">err_vec</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">+</span> <span class="n">h_sig</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">)</span> <span class="o">-</span>
         <span class="n">err_vec</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">-</span> <span class="n">h_sig</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">))</span> <span class="o">/</span>
        <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h_sig</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">Jac_err</span>

<span class="n">N</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">d_err2</span> <span class="o">=</span> <span class="n">Jac_err2</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jacobian matrix of derivatives&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d_err2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighting matrix&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hat</span><span class="p">)</span>
<span class="n">SigHat2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">lin</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">d_err2</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_hat</span> <span class="o">@</span> <span class="n">d_err2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sigma hat squared&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">SigHat2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard errors&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. mu_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. sig_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat2</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jacobian matrix of derivatives
[[ 0.00057977 -0.00191677]
 [-0.00244916  0.00973172]]

Weighting matrix
[[1. 0.]
 [0. 1.]]

Sigma hat squared
[[680416.6956242  172529.83657673]
 [172529.83657673  43810.65660118]]

Standard errors
Std. err. mu_hat= 824.873745262995
Std. err. sig_hat= 209.30995342118365
</pre></div>
</div>
</div>
</div>
<p>Note how big the standard errors are on our GMM estimated parameters using the identity matrix as our optimal weighting matrix.</p>
</section>
<section id="two-moments-two-step-weighting-matrix">
<span id="secgmm-ex-trunc-2mom2st"></span><h4><span class="section-number">18.5.1.2. </span>Two moments, two-step weighting matrix<a class="headerlink" href="#two-moments-two-step-weighting-matrix" title="Permalink to this heading">#</a></h4>
<p>Similar to the MLE problem, the GMM criterion function surface in <a class="reference internal" href="#figgmm-surfcrit1"><span class="std std-numref">Figure 18.2</span></a> looks like it is roughly equal for a specific portion increase of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> together. That is, with these two moments probably have a correspondence of values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> that give roughly the same criterion function value. This issue has two possible solutions.</p>
<ol class="arabic simple">
<li><p>Maybe we need the two-step variance covariance estimator to calculate a “more” optimal weighting matrix <span class="math notranslate nohighlight">\(W\)</span>.</p></li>
<li><p>Maybe our two moments aren’t very good moments for fitting the data.</p></li>
</ol>
<p>Let’s first try the two-step weighting matrix using the steps from Section <a class="reference internal" href="#secgmm-wgt-2step"><span class="std std-ref">Two-step variance-covariance estimator of W</span></a> in equations <a class="reference internal" href="#equation-eqgmm-gmmest-2stp-2varcov">(18.11)</a> and <a class="reference internal" href="#equation-eqgmm-estw-2step">(18.13)</a>.</p>
<p>The following function creates the moment error matrix for this problem defined in <a class="reference internal" href="#equation-eqgmm-gmmest-2stp-errmatpct">(18.10)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_Err_mat2</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the R x N matrix of errors from each</span>
<span class="sd">    observation for each moment. In this function, we have hard coded</span>
<span class="sd">    R = 2.</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals  = (N,) vector, test scores data</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    simple = boolean, =True if errors are simple difference, =False if</span>
<span class="sd">             errors are percent deviation from data moments</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        model_moments()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    R          = integer = 2, hard coded number of moments</span>
<span class="sd">    N          = integer &gt;= R, number of data observations</span>
<span class="sd">    Err_mat    = (R, N) matrix, error by moment and observation data</span>
<span class="sd">    mean_model = scalar, mean value from model</span>
<span class="sd">    var_model  = scalar &gt; 0, variance from model</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: Err_mat</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">R</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xvals</span><span class="p">)</span>
    <span class="n">Err_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">R</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
    <span class="n">mean_data</span> <span class="o">=</span> <span class="n">xvals</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">mean_model</span><span class="p">,</span> <span class="n">var_model</span> <span class="o">=</span> <span class="n">model_moments</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">simple</span><span class="p">:</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">xvals</span> <span class="o">-</span> <span class="n">mean_model</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">((</span><span class="n">mean_data</span> <span class="o">-</span> <span class="n">xvals</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">var_model</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">-</span> <span class="n">mean_model</span><span class="p">)</span> <span class="o">/</span> <span class="n">mean_model</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(((</span><span class="n">mean_data</span> <span class="o">-</span> <span class="n">xvals</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">var_model</span><span class="p">)</span> <span class="o">/</span> <span class="n">var_model</span>

    <span class="k">return</span> <span class="n">Err_mat</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Err_mat</span> <span class="o">=</span> <span class="n">get_Err_mat2</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">VCV2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">Err_mat</span> <span class="o">@</span> <span class="n">Err_mat</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;VCV2=&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VCV2</span><span class="p">)</span>
<span class="n">W_hat2</span> <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">VCV2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W_hat2=&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hat2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>VCV2=
[[ 0.0669623  -0.43803414]
 [-0.43803414  4.78818521]]

W_hat2=
[[37.18863472  3.40210144]
 [ 3.40210144  0.52007942]]
</pre></div>
</div>
</div>
</div>
<p>Now we can perform the GMM estimation with the optimal two-step weighting matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note that this takes a little time because the intgr.quad() commands</span>
<span class="c1"># are a little slow</span>
<span class="n">mu_init</span> <span class="o">=</span> <span class="mi">400</span>  <span class="c1"># alternative initial guess is mu_GMM1</span>
<span class="n">sig_init</span> <span class="o">=</span> <span class="mi">60</span>   <span class="c1"># alternative initial guess is sig_GMM1</span>
<span class="n">params_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_init</span><span class="p">,</span> <span class="n">sig_init</span><span class="p">])</span>
<span class="n">gmm_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat2</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">params_init</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">gmm_args</span><span class="p">),</span>
                       <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
<span class="n">mu_GMM2</span><span class="p">,</span> <span class="n">sig_GMM2</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu_GMM2=&#39;</span><span class="p">,</span> <span class="n">mu_GMM2</span><span class="p">,</span> <span class="s1">&#39; sig_GMM2=&#39;</span><span class="p">,</span> <span class="n">sig_GMM2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scipy.optimize.minimize results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mu_GMM2= 620.6308663064567  sig_GMM2= 198.31485537445292

Scipy.optimize.minimize results:
  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL
  success: True
   status: 0
      fun: 3.3264185347113687e-07
        x: [ 6.206e+02  1.983e+02]
      nit: 15
      jac: [-1.827e-06  4.719e-06]
     nfev: 48
     njev: 16
 hess_inv: &lt;2x2 LbfgsInvHessProduct with dtype=float64&gt;
</pre></div>
</div>
</div>
</div>
<p>The GMM estimates here with the two-step weighting matrix are pretty similar to the estimates from the previous section that simply used the identity matrix as the weighting matrix. However, the estimated results here are sensitive to the initial guess.</p>
<p>But the real benefit of the two-step weighting matrix shows up in the much smaller (more efficient) estimated standard errors for the GMM parameter estimates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">d_err2_2</span> <span class="o">=</span> <span class="n">Jac_err2</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM2</span><span class="p">,</span> <span class="n">sig_GMM2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jacobian matrix of derivatives&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d_err2_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighting matrix&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hat2</span><span class="p">)</span>
<span class="n">SigHat2_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">lin</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">d_err2_2</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_hat2</span> <span class="o">@</span> <span class="n">d_err2_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sigma hat squared&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">SigHat2_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard errors&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. mu_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat2_2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. sig_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat2_2</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jacobian matrix of derivatives
[[ 0.00058186 -0.00191917]
 [-0.00245583  0.00974327]]

Weighting matrix
[[37.18863472  3.40210144]
 [ 3.40210144  0.52007942]]

Sigma hat squared
[[51715.1351509  16316.40623475]
 [16316.40623475  5252.98677153]]

Standard errors
Std. err. mu_hat= 227.409619741333
Std. err. sig_hat= 72.47749148202472
</pre></div>
</div>
</div>
</div>
</section>
<section id="four-moments-identity-weighting-matrix">
<span id="secgmm-ex-trunc-4momi"></span><h4><span class="section-number">18.5.1.3. </span>Four moments, identity weighting matrix<a class="headerlink" href="#four-moments-identity-weighting-matrix" title="Permalink to this heading">#</a></h4>
<p>Using a better weighting matrix didn’t improve our estimates or fit very much it did improve the standard errors of our estimates. To get the right fit, we might need to choose different moments. Let’s try an overidentified model <span class="math notranslate nohighlight">\(R&gt;K\)</span>, where we estimate <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> of the truncated normal distribution <span class="math notranslate nohighlight">\(K=2\)</span> using the following four moments <span class="math notranslate nohighlight">\(R=4\)</span>.</p>
<ol class="arabic simple">
<li><p>The percent of observations greater than 430 (between 430 and 450)</p></li>
<li><p>The percent of observations between 320 and 430</p></li>
<li><p>The percent of observations between 220 and 320</p></li>
<li><p>The percent of observations less than 220 (between 0 and 220)</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">data_moments4</span><span class="p">(</span><span class="n">xvals</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the four data moments for GMM</span>
<span class="sd">    (binpct_1, binpct_2, binpct_3, binpct_4).</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals = (N,) vector, test scores data</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION: None</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    bpct_1_dat = scalar in [0, 1], percent of observations</span>
<span class="sd">                 0 &lt;= x &lt; 220</span>
<span class="sd">    bpct_2_dat = scalar in [0, 1], percent of observations</span>
<span class="sd">                 220 &lt;= x &lt; 320</span>
<span class="sd">    bpct_3_dat = scalar in [0, 1], percent of observations</span>
<span class="sd">                 320 &lt;= x &lt; 430</span>
<span class="sd">    bpct_4_dat = scalar in [0, 1], percent of observations</span>
<span class="sd">                 430 &lt;= x &lt;= 450</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: bpct_1, bpct_2, bpct_3, bpct_4</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">bpct_1_dat</span> <span class="o">=</span> <span class="n">xvals</span><span class="p">[</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">220</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">xvals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">bpct_2_dat</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span><span class="p">[(</span><span class="n">xvals</span> <span class="o">&gt;=</span><span class="mi">220</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">320</span><span class="p">)]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span>
                  <span class="n">xvals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">bpct_3_dat</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span><span class="p">[(</span><span class="n">xvals</span> <span class="o">&gt;=</span><span class="mi">320</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">430</span><span class="p">)]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span>
                  <span class="n">xvals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">bpct_4_dat</span> <span class="o">=</span> <span class="n">xvals</span><span class="p">[</span><span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">430</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">xvals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">bpct_1_dat</span><span class="p">,</span> <span class="n">bpct_2_dat</span><span class="p">,</span> <span class="n">bpct_3_dat</span><span class="p">,</span> <span class="n">bpct_4_dat</span>


<span class="k">def</span> <span class="nf">model_moments4</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the four model moments for GMM</span>
<span class="sd">    (binpct_1, binpct_2, binpct_3, binpct_4).</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        trunc_norm_pdf()</span>
<span class="sd">        xfx()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    bpct_1_mod = scalar in [0, 1], percent of model observations in</span>
<span class="sd">                 bin 1</span>
<span class="sd">    bp_1_err   = scalar &gt; 0, estimated error in the computation of the</span>
<span class="sd">                 integral for bpct_1_mod</span>
<span class="sd">    bpct_2_mod = scalar in [0, 1], percent of model observations in</span>
<span class="sd">                 bin 2</span>
<span class="sd">    bp_2_err   = scalar &gt; 0, estimated error in the computation of the</span>
<span class="sd">                 integral for bpct_2_mod</span>
<span class="sd">    bpct_3_mod = scalar in [0, 1], percent of model observations in</span>
<span class="sd">                 bin 3</span>
<span class="sd">    bp_3_err   = scalar &gt; 0, estimated error in the computation of the</span>
<span class="sd">                 integral for bpct_3_mod</span>
<span class="sd">    bpct_4_mod = scalar in [0, 1], percent of model observations in</span>
<span class="sd">                 bin 4</span>
<span class="sd">    bp_4_err   = scalar &gt; 0, estimated error in the computation of the</span>
<span class="sd">                 integral for bpct_4_mod</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: bpct_1_mod, bpct_2_mod, bpct_3_mod, bpct_4_mod</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">xfx</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bpct_1_mod</span><span class="p">,</span> <span class="n">bp_1_err</span><span class="p">)</span> <span class="o">=</span> <span class="n">intgr</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">xfx</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">220</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bpct_2_mod</span><span class="p">,</span> <span class="n">bp_2_err</span><span class="p">)</span> <span class="o">=</span> <span class="n">intgr</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">xfx</span><span class="p">,</span> <span class="mi">220</span><span class="p">,</span> <span class="mi">320</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bpct_3_mod</span><span class="p">,</span> <span class="n">bp_3_err</span><span class="p">)</span> <span class="o">=</span> <span class="n">intgr</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">xfx</span><span class="p">,</span> <span class="mi">320</span><span class="p">,</span> <span class="mi">430</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bpct_4_mod</span><span class="p">,</span> <span class="n">bp_4_err</span><span class="p">)</span> <span class="o">=</span> <span class="n">intgr</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">xfx</span><span class="p">,</span> <span class="mi">430</span><span class="p">,</span> <span class="mi">450</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">bpct_1_mod</span><span class="p">,</span> <span class="n">bpct_2_mod</span><span class="p">,</span> <span class="n">bpct_3_mod</span><span class="p">,</span> <span class="n">bpct_4_mod</span>


<span class="k">def</span> <span class="nf">err_vec4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the vector of moment errors (in percent</span>
<span class="sd">    deviation from the data moment vector) for GMM.</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals  = (N,) vector, test scores data</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    simple = boolean, =True if errors are simple difference, =False if</span>
<span class="sd">             errors are percent deviation from data moments</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        data_moments4()</span>
<span class="sd">        model_moments4()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    mean_data  = scalar, mean value of data</span>
<span class="sd">    var_data   = scalar &gt; 0, variance of data</span>
<span class="sd">    moms_data  = (2, 1) matrix, column vector of two data moments</span>
<span class="sd">    mean_model = scalar, mean value from model</span>
<span class="sd">    var_model  = scalar &gt; 0, variance from model</span>
<span class="sd">    moms_model = (2, 1) matrix, column vector of two model moments</span>
<span class="sd">    err_vec    = (2, 1) matrix, column vector of two moment error</span>
<span class="sd">                 functions</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: err_vec</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">bpct_1_dat</span><span class="p">,</span> <span class="n">bpct_2_dat</span><span class="p">,</span> <span class="n">bpct_3_dat</span><span class="p">,</span> <span class="n">bpct_4_dat</span> <span class="o">=</span> \
        <span class="n">data_moments4</span><span class="p">(</span><span class="n">xvals</span><span class="p">)</span>
    <span class="n">moms_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">bpct_1_dat</span><span class="p">],</span> <span class="p">[</span><span class="n">bpct_2_dat</span><span class="p">],</span> <span class="p">[</span><span class="n">bpct_3_dat</span><span class="p">],</span>
                          <span class="p">[</span><span class="n">bpct_4_dat</span><span class="p">]])</span>
    <span class="n">bpct_1_mod</span><span class="p">,</span> <span class="n">bpct_2_mod</span><span class="p">,</span> <span class="n">bpct_3_mod</span><span class="p">,</span> <span class="n">bpct_4_mod</span> <span class="o">=</span> \
        <span class="n">model_moments4</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="n">moms_model</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">bpct_1_mod</span><span class="p">],</span> <span class="p">[</span><span class="n">bpct_2_mod</span><span class="p">],</span> <span class="p">[</span><span class="n">bpct_3_mod</span><span class="p">],</span>
                          <span class="p">[</span><span class="n">bpct_4_mod</span><span class="p">]])</span>
    <span class="k">if</span> <span class="n">simple</span><span class="p">:</span>
        <span class="n">err_vec</span> <span class="o">=</span> <span class="n">moms_model</span> <span class="o">-</span> <span class="n">moms_data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">err_vec</span> <span class="o">=</span> <span class="p">(</span><span class="n">moms_model</span> <span class="o">-</span> <span class="n">moms_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">moms_data</span>

    <span class="k">return</span> <span class="n">err_vec</span>


<span class="k">def</span> <span class="nf">criterion4</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the GMM weighted sum of squared moment errors</span>
<span class="sd">    criterion function value given parameter values and an estimate of</span>
<span class="sd">    the weighting matrix.</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    params = (2,) vector, ([mu, sigma])</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    args   = length 3 tuple, (xvals, cutoff, W_hat)</span>
<span class="sd">    xvals  = (N,) vector, values of the truncated normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    W_hat  = (R, R) matrix, estimate of optimal weighting matrix</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        err_vec4()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    err        = (4, 1) matrix, column vector of four moment error</span>
<span class="sd">                 functions</span>
<span class="sd">    crit_val   = scalar &gt; 0, GMM criterion function value</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: crit_val</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">xvals</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">args</span>
    <span class="n">err</span> <span class="o">=</span> <span class="n">err_vec4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">crit_val</span> <span class="o">=</span> <span class="n">err</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W</span> <span class="o">@</span> <span class="n">err</span>

    <span class="k">return</span> <span class="n">crit_val</span>
</pre></div>
</div>
</div>
</div>
<p>Before performing the estimation, let’s see what these four model moments would be relative to the data moments with the first GMM estimates from the two-moment GMM estimation with the identity weighting matrix from Section <a class="reference internal" href="#secgmm-ex-trunc-2momi"><span class="std std-ref">Two moments, identity weighting matrix</span></a> of <span class="math notranslate nohighlight">\(\mu\approx 622\)</span> and <span class="math notranslate nohighlight">\(\sigma\approx 199\)</span>. Let’s also look at the resulting criterion function at those values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;2-moment mu_GMM1 is:&quot;</span><span class="p">,</span> <span class="n">mu_GMM1</span><span class="p">,</span> <span class="s2">&quot;, and 2-moment sig_GMM1 is:&quot;</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data moments are the following:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data_moments4</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model moments at the GMM1 estimates are the following:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_moments4</span><span class="p">(</span><span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">450</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMM criterion function value at GMM1 estimates with identity wgt mat:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">criterion4</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2-moment mu_GMM1 is: 622.0452991337212 , and 2-moment sig_GMM1 is: 198.72061665917036

Data moments are the following:
(0.08695652173913043, 0.17391304347826086, 0.6894409937888198, 0.049689440993788817)

Model moments at the GMM1 estimates are the following:
(0.10733213606963418, 0.22206800774330326, 0.533465129056967, 0.13713472713009578)

GMM criterion function value at GMM1 estimates with identity wgt mat:
3.279780799994561
</pre></div>
</div>
</div>
</div>
<p>Now let’s perform the GMM estimation of the two parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> using the four moments described above and the identity weighting matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note that this takes a little time because the intgr.quad() commands</span>
<span class="c1"># are a little slow</span>
<span class="n">mu_init</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">sig_init</span> <span class="o">=</span> <span class="mi">70</span>
<span class="n">params_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_init</span><span class="p">,</span> <span class="n">sig_init</span><span class="p">])</span>
<span class="n">W_hat1_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">gmm_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat1_4</span><span class="p">)</span>
<span class="n">results_4</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">criterion4</span><span class="p">,</span> <span class="n">params_init</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">gmm_args</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span>
    <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span> <span class="o">=</span> <span class="n">results_4</span><span class="o">.</span><span class="n">x</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu_GMM1_4=&#39;</span><span class="p">,</span> <span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="s1">&#39; sig_GMM1_4=&#39;</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scipy.optimize.minimize results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mu_GMM1_4= 361.64944545585274  sig_GMM1_4= 92.132508955815

Scipy.optimize.minimize results:
  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL
  success: True
   status: 0
      fun: 0.9585428695214522
        x: [ 3.616e+02  9.213e+01]
      nit: 9
      jac: [-4.363e-06 -4.441e-07]
     nfev: 30
     njev: 10
 hess_inv: &lt;2x2 LbfgsInvHessProduct with dtype=float64&gt;
</pre></div>
</div>
</div>
</div>
<p>Let’s compare the model moments at these new GMM estimates to the data moments and the associated criterion function value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;4-moment mu_GMM1 is:&quot;</span><span class="p">,</span> <span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="s2">&quot;, and 4-moment sig_GMM1 is:&quot;</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data moments are the following:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data_moments4</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model moments at the GMM1_4 estimates are the following:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_moments4</span><span class="p">(</span><span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">450</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMM criterion function value at GMM1_4 estimates with identity wgt mat:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">criterion4</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat1_4</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4-moment mu_GMM1 is: 361.64944545585274 , and 4-moment sig_GMM1 is: 92.132508955815

Data moments are the following:
(0.08695652173913043, 0.17391304347826086, 0.6894409937888198, 0.049689440993788817)

Model moments at the GMM1_4 estimates are the following:
(0.07465165923992131, 0.3170509469322965, 0.535759895979849, 0.07253749784793316)

GMM criterion function value at GMM1_4 estimates with identity wgt mat:
0.9585428695214522
</pre></div>
</div>
</div>
</div>
<p>The 4-moment GMM estimates with the identity weighting matrix of <span class="math notranslate nohighlight">\(\hat{mu}\approx 362\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}\approx 92\)</span> have model moments that match the data moments much more closely that those associated with the 2-moment GMM estimates shown above. And the criterion function value of this new estimate is much lower (<span class="math notranslate nohighlight">\(\sim 0.96\)</span>) than that of the two-moment GMM estimates (<span class="math notranslate nohighlight">\(\sim 3.28\)</span>).</p>
<p><a class="reference internal" href="#figgmm-econscores4mom2mom"><span class="std std-numref">Figure 18.3</span></a> shows the histogram of the intermediate macroeconomics scores with the 4-moment estimated truncated normal distribution and the 2-moment estated distribution from Section <a class="reference internal" href="#secgmm-ex-trunc-2momi"><span class="std std-ref">Two moments, identity weighting matrix</span></a>.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the histogram of the data</span>
<span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Intermediate macro scores: 2011-2012&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Total points&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Percent of scores&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">550</span><span class="p">])</span>  <span class="c1"># This gives the xmin and xmax to be plotted&quot;</span>

<span class="c1"># Plot the 4-moment GMM estimated distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">dist_pts</span><span class="p">,</span>
    <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">dist_pts</span><span class="p">,</span> <span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;4-moment: $\hat{\mu}_</span><span class="si">{GMM}</span><span class="s1">$=362,$\hat{\sigma}_</span><span class="si">{GMM}</span><span class="s1">$=92&#39;</span>
<span class="p">)</span>

<span class="c1"># Plot the 2-moment GMM estimated distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">dist_pts</span><span class="p">,</span>
    <span class="n">trunc_norm_pdf</span><span class="p">(</span><span class="n">dist_pts</span><span class="p">,</span> <span class="n">mu_GMM1</span><span class="p">,</span> <span class="n">sig_GMM1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;2-moment: $\hat{\mu}_</span><span class="si">{GMM}</span><span class="s1">$=622,$\hat{\sigma}_</span><span class="si">{GMM}</span><span class="s1">$=199&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="figgmm-econscores4mom2mom">
<a class="reference internal image-reference" href="../_images/Econ381scores_4mom2mom.png"><img alt="../_images/Econ381scores_4mom2mom.png" src="../_images/Econ381scores_4mom2mom.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18.3 </span><span class="caption-text">GMM estimated truncated normal distributions to fit intermediate macroeconomics test score data: 4-moment estimation versus 2-moment estimation.</span><a class="headerlink" href="#figgmm-econscores4mom2mom" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>We can compute the estimator of the variance-covariance matrix <span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span> of the GMM parameter estimator by computing the Jacobian of the error vector. In this case, the Jacobian <span class="math notranslate nohighlight">\(d(x|\theta)\)</span> is <span class="math notranslate nohighlight">\(R\times K = 4\times 2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Jac_err4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function computes the Jacobian matrix of partial derivatives of the</span>
<span class="sd">    R x 1 moment error vector e(x|theta) with respect to the K parameters</span>
<span class="sd">    theta_i in the K x 1 parameter vector theta. The resulting matrix is</span>
<span class="sd">    R x K Jacobian.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">Jac_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">h_mu</span> <span class="o">=</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">mu</span>
    <span class="n">h_sig</span> <span class="o">=</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">sigma</span>
    <span class="n">Jac_err</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">err_vec4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">h_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">)</span> <span class="o">-</span>
         <span class="n">err_vec4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">h_mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">))</span> <span class="o">/</span>
        <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h_mu</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">Jac_err</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">err_vec4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">+</span> <span class="n">h_sig</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">)</span> <span class="o">-</span>
         <span class="n">err_vec4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">-</span> <span class="n">h_sig</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="p">))</span> <span class="o">/</span>
        <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h_sig</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">Jac_err</span>

<span class="n">d_err4</span> <span class="o">=</span> <span class="n">Jac_err4</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jacobian matrix of derivatives&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d_err4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighting matrix&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hat1_4</span><span class="p">)</span>
<span class="n">SigHat4</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">lin</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">d_err4</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_hat1_4</span> <span class="o">@</span> <span class="n">d_err4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sigma hat squared&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">SigHat4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard errors&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. mu_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat4</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. sig_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat4</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jacobian matrix of derivatives
[[-0.01552584  0.03086035]
 [-0.01186598  0.00386864]
 [ 0.00363826 -0.00488294]
 [ 0.01822034  0.00020491]]

Weighting matrix
[[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]

Sigma hat squared
[[14.31483056  7.78510557]
 [ 7.78510557 10.50016556]]

Standard errors
Std. err. mu_hat= 3.7834944903706673
Std. err. sig_hat= 3.240395895001008
</pre></div>
</div>
</div>
</div>
<p>Note how much tighter the standard errors are here with these four moments than they were in the econometric models of Sections <a class="reference internal" href="#secgmm-ex-trunc-2momi"><span class="std std-ref">Two moments, identity weighting matrix</span></a> and <a class="reference internal" href="#secgmm-ex-trunc-2mom2st"><span class="std std-ref">Two moments, two-step weighting matrix</span></a>.</p>
<p><a class="reference internal" href="#figgmm-surfcrit4"><span class="std std-numref">Figure 18.4</span></a> shows the surface of the criterion function of this 4-moment problem in the neighborhood of the GMM estimate of <span class="math notranslate nohighlight">\(\hat{\mu}_{GMM}\approx 362\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}_{GMM}\approx 92\)</span>. This provides more evidence that the GMM estimates are a global minimum of the criterion function. There less of a flat ridge in <span class="math notranslate nohighlight">\((\mu,\sigma)\)</span>-space as was the case in the 2-moment GMM problem and the MLE problems.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">critfunc_GMM1_4</span> <span class="o">=</span> <span class="n">criterion4</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">]),</span>
                            <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat1_4</span><span class="p">)</span>

<span class="n">mu_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">330</span><span class="p">,</span> <span class="mi">390</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
<span class="n">sig_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">critfunc_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="k">for</span> <span class="n">mu_ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">90</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">sig_ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">critfunc_vals</span><span class="p">[</span><span class="n">mu_ind</span><span class="p">,</span> <span class="n">sig_ind</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">criterion4</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_vals</span><span class="p">[</span><span class="n">mu_ind</span><span class="p">],</span> <span class="n">sig_vals</span><span class="p">[</span><span class="n">sig_ind</span><span class="p">]]),</span>
                       <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat1_4</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sig_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">mu_vals</span><span class="p">,</span> <span class="n">sig_vals</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;3d&quot;</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">mu_mesh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">sig_mesh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">critfunc_vals</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">,</span> <span class="n">critfunc_GMM1_4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span>
           <span class="n">s</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GMM estimate&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">elev</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">azim</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">roll</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Criterion function surface for values of mu and sigma&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\sigma$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Criterion func.&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="figgmm-surfcrit4">
<a class="reference internal image-reference" href="../../images/gmm/Econ381scores_SurfaceCrit4.png"><img alt="../../images/gmm/Econ381scores_SurfaceCrit4.png" src="../../images/gmm/Econ381scores_SurfaceCrit4.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18.4 </span><span class="caption-text">Surface of the 4 moment, identity weighting matrix GMM criterion function for values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> in the neighborhood of the GMM estimate. The scatter point represents the criterion function value for the GMM estimate.</span><a class="headerlink" href="#figgmm-surfcrit4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="four-moments-two-step-weighting-matrix">
<span id="secgmm-ex-trunc-4mom2st"></span><h4><span class="section-number">18.5.1.4. </span>Four moments, two-step weighting matrix<a class="headerlink" href="#four-moments-two-step-weighting-matrix" title="Permalink to this heading">#</a></h4>
<p>Let’s see how much things change in this 4-moment case if we use the two-step estimator for the optimal weighting matrix <span class="math notranslate nohighlight">\(W\)</span> instead of the identity matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_Err_mat4</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    This function computes the R x N matrix of errors from each</span>
<span class="sd">    observation for each moment. In this function, we have hard coded</span>
<span class="sd">    R = 4.</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    INPUTS:</span>
<span class="sd">    xvals  = (N,) vector, test scores data</span>
<span class="sd">    mu     = scalar, mean of the normally distributed random variable</span>
<span class="sd">    sigma  = scalar &gt; 0, standard deviation of the normally distributed</span>
<span class="sd">             random variable</span>
<span class="sd">    cut_lb = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar lower bound value of distribution. Values below</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    cut_ub = scalar or string, =&#39;None&#39; if no cutoff is given, otherwise</span>
<span class="sd">             is scalar upper bound value of distribution. Values above</span>
<span class="sd">             this value have zero probability</span>
<span class="sd">    simple = boolean, =True if errors are simple difference, =False if</span>
<span class="sd">             errors are percent deviation from data moments</span>

<span class="sd">    OTHER FUNCTIONS AND FILES CALLED BY THIS FUNCTION:</span>
<span class="sd">        model_moments()</span>

<span class="sd">    OBJECTS CREATED WITHIN FUNCTION:</span>
<span class="sd">    R          = 2, hard coded number of moments</span>
<span class="sd">    N          = integer &gt;= R, number of data observations</span>
<span class="sd">    Err_mat    = (R, N) matrix, error by moment and observation data</span>
<span class="sd">    mean_model = scalar, mean value from model</span>
<span class="sd">    var_model  = scalar &gt; 0, variance from model</span>

<span class="sd">    FILES CREATED BY THIS FUNCTION: None</span>

<span class="sd">    RETURNS: Err_mat</span>
<span class="sd">    --------------------------------------------------------------------</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">R</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xvals</span><span class="p">)</span>
    <span class="n">Err_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">R</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
    <span class="n">pct_1_mod</span><span class="p">,</span> <span class="n">pct_2_mod</span><span class="p">,</span> <span class="n">pct_3_mod</span><span class="p">,</span> <span class="n">pct_4_mod</span> <span class="o">=</span> \
        <span class="n">model_moments4</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">cut_lb</span><span class="p">,</span> <span class="n">cut_ub</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">simple</span><span class="p">:</span>
        <span class="n">pts_in_grp1</span> <span class="o">=</span> <span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">220</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">pts_in_grp1</span> <span class="o">-</span> <span class="n">pct_1_mod</span>
        <span class="n">pts_in_grp2</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">220</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">320</span><span class="p">)</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">pts_in_grp2</span> <span class="o">-</span> <span class="n">pct_2_mod</span>
        <span class="n">pts_in_grp3</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">320</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">430</span><span class="p">)</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">pts_in_grp3</span> <span class="o">-</span> <span class="n">pct_3_mod</span>
        <span class="n">pts_in_grp4</span> <span class="o">=</span> <span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">430</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">pts_in_grp4</span> <span class="o">-</span> <span class="n">pct_4_mod</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pts_in_grp1</span> <span class="o">=</span> <span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">220</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pts_in_grp1</span> <span class="o">-</span> <span class="n">pct_1_mod</span><span class="p">)</span> <span class="o">/</span> <span class="n">pct_1_mod</span>
        <span class="n">pts_in_grp2</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">220</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">320</span><span class="p">)</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pts_in_grp2</span> <span class="o">-</span> <span class="n">pct_2_mod</span><span class="p">)</span> <span class="o">/</span> <span class="n">pct_2_mod</span>
        <span class="n">pts_in_grp3</span> <span class="o">=</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">320</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xvals</span> <span class="o">&lt;</span> <span class="mi">430</span><span class="p">)</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pts_in_grp3</span> <span class="o">-</span> <span class="n">pct_3_mod</span><span class="p">)</span> <span class="o">/</span> <span class="n">pct_3_mod</span>
        <span class="n">pts_in_grp4</span> <span class="o">=</span> <span class="n">xvals</span> <span class="o">&gt;=</span> <span class="mi">430</span>
        <span class="n">Err_mat</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pts_in_grp4</span> <span class="o">-</span> <span class="n">pct_4_mod</span><span class="p">)</span> <span class="o">/</span> <span class="n">pct_4_mod</span>

    <span class="k">return</span> <span class="n">Err_mat</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Err_mat4</span> <span class="o">=</span> <span class="n">get_Err_mat4</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM1_4</span><span class="p">,</span> <span class="n">sig_GMM1_4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">VCV2_4</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">Err_mat4</span> <span class="o">@</span> <span class="n">Err_mat4</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;VCV2_4=&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VCV2_4</span><span class="p">)</span>
<span class="c1"># We use the pseudo-inverse command here because the VCV matrix is</span>
<span class="c1"># poorly conditioned</span>
<span class="n">W_hat2_4</span> <span class="o">=</span> <span class="n">lin</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">VCV2_4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W_hat2_4=&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hat2_4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>VCV2_4=
[[14.27388248 -0.71336383 -1.45167736 -0.8498477 ]
 [-0.71336383  1.63304445 -0.83538039 -0.23355073]
 [-1.45167736 -0.83538039  0.82821591 -0.97186426]
 [-0.8498477  -0.23355073 -0.97186426  9.07359554]]

W_hat2_4=
[[ 0.06838551 -0.00850159 -0.00505903  0.00414641]
 [-0.00850159  0.34794467 -0.20203496 -0.01984217]
 [-0.00505903 -0.20203496  0.12073767 -0.00349282]
 [ 0.00414641 -0.01984217 -0.00349282  0.10825784]]
</pre></div>
</div>
</div>
</div>
<p>With the two-step optimal weighting matrix, we can estimate this 4-moment problem by GMM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note that this takes a little time because the intgr.quad() commands</span>
<span class="c1"># are a little slow</span>
<span class="n">mu_init</span> <span class="o">=</span> <span class="n">mu_GMM1_4</span>
<span class="n">sig_init</span> <span class="o">=</span> <span class="n">sig_GMM1_4</span>
<span class="n">params_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_init</span><span class="p">,</span> <span class="n">sig_init</span><span class="p">])</span>
<span class="n">gmm_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat2_4</span><span class="p">)</span>
<span class="n">results2_4</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">criterion4</span><span class="p">,</span> <span class="n">params_init</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">gmm_args</span><span class="p">),</span>
                          <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mf">1e-10</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
<span class="n">mu_GMM2_4</span><span class="p">,</span> <span class="n">sig_GMM2_4</span> <span class="o">=</span> <span class="n">results2_4</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu_GMM2_4=&#39;</span><span class="p">,</span> <span class="n">mu_GMM2_4</span><span class="p">,</span> <span class="s1">&#39; sig_GMM2_4=&#39;</span><span class="p">,</span> <span class="n">sig_GMM2_4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scipy.optimize.minimize results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results2_4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2846/3397713799.py:48: RuntimeWarning: invalid value encountered in scalar divide
  pdf_vals    = ((1/(sigma * np.sqrt(2 * np.pi)) *
/tmp/ipykernel_2846/4026398128.py:82: IntegrationWarning: The occurrence of roundoff error is detected, which prevents 
  the requested tolerance from being achieved.  The error may be 
  underestimated.
  (bpct_1_mod, bp_1_err) = intgr.quad(xfx, 0.0, 220)
/tmp/ipykernel_2846/4026398128.py:83: IntegrationWarning: The occurrence of roundoff error is detected, which prevents 
  the requested tolerance from being achieved.  The error may be 
  underestimated.
  (bpct_2_mod, bp_2_err) = intgr.quad(xfx, 220, 320)
/tmp/ipykernel_2846/4026398128.py:84: IntegrationWarning: The occurrence of roundoff error is detected, which prevents 
  the requested tolerance from being achieved.  The error may be 
  underestimated.
  (bpct_3_mod, bp_3_err) = intgr.quad(xfx, 320, 430)
/tmp/ipykernel_2846/4026398128.py:85: IntegrationWarning: The occurrence of roundoff error is detected, which prevents 
  the requested tolerance from being achieved.  The error may be 
  underestimated.
  (bpct_4_mod, bp_4_err) = intgr.quad(xfx, 430, 450)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mu_GMM2_4= 365.2119545518343  sig_GMM2_4= 49.02027875393562

Scipy.optimize.minimize results:
  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL
  success: True
   status: 0
      fun: 0.0677439730049783
        x: [ 3.652e+02  4.902e+01]
      nit: 10
      jac: [-1.402e-06  2.577e-06]
     nfev: 66
     njev: 22
 hess_inv: &lt;2x2 LbfgsInvHessProduct with dtype=float64&gt;
</pre></div>
</div>
</div>
</div>
<p>In this case, the two-step estimator creates a fairly significant change in the estimates from that of the previous section with the identity weighting matrix. The estimate of <span class="math notranslate nohighlight">\(\mu\)</span> stays roughly the same, but the estimate of <span class="math notranslate nohighlight">\(\sigma\)</span> is one-half the size–from <span class="math notranslate nohighlight">\((\mu=362,\sigma=92)\)</span> with the idenity weighting matrix to this estimate of <span class="math notranslate nohighlight">\((\mu=365,\sigma=49)\)</span> with the two-step weighting matrix.</p>
<p>The criterion function surface in <a class="reference internal" href="#figgmm-surfcrit4-2"><span class="std std-numref">Figure 18.5</span></a> shows the criterion function for different values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>. It has a clear minimum in a certain area. But it also has some really interesting nonlinearities.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">critfunc_GMM2_4</span> <span class="o">=</span> <span class="n">criterion4</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_GMM2_4</span><span class="p">,</span> <span class="n">sig_GMM2_4</span><span class="p">]),</span>
                             <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat2_4</span><span class="p">)</span>

<span class="n">mu_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">330</span><span class="p">,</span> <span class="mi">390</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
<span class="n">sig_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">critfunc_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="k">for</span> <span class="n">mu_ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">90</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">sig_ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">critfunc_vals</span><span class="p">[</span><span class="n">mu_ind</span><span class="p">,</span> <span class="n">sig_ind</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">criterion4</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mu_vals</span><span class="p">[</span><span class="n">mu_ind</span><span class="p">],</span> <span class="n">sig_vals</span><span class="p">[</span><span class="n">sig_ind</span><span class="p">]]),</span>
                       <span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="n">W_hat2_4</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">mu_mesh</span><span class="p">,</span> <span class="n">sig_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">mu_vals</span><span class="p">,</span> <span class="n">sig_vals</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;3d&quot;</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">mu_mesh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">sig_mesh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">critfunc_vals</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu_GMM2_4</span><span class="p">,</span> <span class="n">sig_GMM2_4</span><span class="p">,</span> <span class="n">critfunc_GMM2_4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span>
           <span class="n">s</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GMM estimate&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">elev</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">azim</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">roll</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Criterion function surface for values of mu and sigma&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\sigma$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Criterion func.&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="figgmm-surfcrit4-2">
<a class="reference internal image-reference" href="../_images/Econ381scores_SurfaceCrit4_2.png"><img alt="../_images/Econ381scores_SurfaceCrit4_2.png" src="../_images/Econ381scores_SurfaceCrit4_2.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18.5 </span><span class="caption-text">Surface of the 4 moment, two-step weighting matrix GMM criterion function for values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> in the neighborhood of the GMM estimate. The scatter point represents the criterion function value for the GMM estimate.</span><a class="headerlink" href="#figgmm-surfcrit4-2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>We can compute the estimator of the variance-covariance matrix <span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span> of the GMM parameter estimate by computing the Jacobian of the error vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d_err4_2</span> <span class="o">=</span> <span class="n">Jac_err4</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_GMM2_4</span><span class="p">,</span> <span class="n">sig_GMM2_4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jacobian matrix of derivatives&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d_err4_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighting matrix&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">W_hat2_4</span><span class="p">)</span>
<span class="n">SigHat4_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">lin</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">d_err4_2</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_hat2_4</span> <span class="o">@</span> <span class="n">d_err4_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sigma hat squared&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">SigHat4_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard errors&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. mu_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat4_2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Std. err. sig_hat=&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">SigHat4_2</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jacobian matrix of derivatives
[[-0.00117936  0.00365723]
 [-0.02929431  0.03113041]
 [ 0.00500696 -0.01059365]
 [ 0.03512239  0.03163025]]

Weighting matrix
[[ 0.06838551 -0.00850159 -0.00505903  0.00414641]
 [-0.00850159  0.34794467 -0.20203496 -0.01984217]
 [-0.00505903 -0.20203496  0.12073767 -0.00349282]
 [ 0.00414641 -0.01984217 -0.00349282  0.10825784]]

Sigma hat squared
[[16.67939406  8.97258352]
 [ 8.97258352 15.99986405]]

Standard errors
Std. err. mu_hat= 4.084041388327125
Std. err. sig_hat= 3.9999830066043858
</pre></div>
</div>
</div>
</div>
<p>In this case, the standard errors on the two GMM parameter estimates are a little larger than those from the previous section with the identity weighting matrix. But the standard errors here are still small.</p>
</section>
</section>
<section id="unconditional-and-conditional-expectations-instruments-and-moments">
<span id="secgmm-ex-condexp"></span><h3><span class="section-number">18.5.2. </span>Unconditional and conditional expectations, instruments, and moments<a class="headerlink" href="#unconditional-and-conditional-expectations-instruments-and-moments" title="Permalink to this heading">#</a></h3>
<p>Most standard treatments of the generalized method of moments estimator in econometrics textbooks start with this principle and this selection of moments. However, this notebook follows the progression of starting with the most general treatment of GMM and then covering these special cases.</p>
<p>In stochastic models, the assumed data generating process might have one or more characterizing equations that involve an unconditional expectation. The unconditional expectation is a strong assumption with many implications on conditional expectations that can create moments for identifying parameters using GMM. In econometric models, these unconditional expectations often show up as an assumption on the error term of one or more of the equations. Note that this is a minimal assumption and does not require knowledge of the distribution of the error term.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-linreg">
<span class="eqno">(18.32)<a class="headerlink" href="#equation-eqgmm-ex-condexp-linreg" title="Permalink to this equation">#</a></span>\[    y_i = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \varepsilon_i \quad\text{where}\quad E\left[\varepsilon_i\right] = 0\]</div>
<p>In a macroeconomic model like the <span id="id8">[<a class="reference internal" href="../CompMethods_references.html#id8" title="William A. Brock and Leonard J. Mirman. Optimal economic growth and uncertainty: the discounted case. Journal of Economic Theory, 4(3):479-513, June 1972.">Brock and Mirman, 1972</a>]</span> model (characterized by the following five equations), unconditional expectations show up in two places. The first is in the Euler equation for consumption <a class="reference internal" href="#equation-eqgmm-ex-condexp-eulc">(18.33)</a>, and the second is on the error term in the law of motion for the productivity shock <a class="reference internal" href="#equation-eqgmm-ex-condexp-z">(18.37)</a>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-eulc">
<span class="eqno">(18.33)<a class="headerlink" href="#equation-eqgmm-ex-condexp-eulc" title="Permalink to this equation">#</a></span>\[    \left(c_t\right)^{-1} = \beta E\left[r_{t+1}\left(c_{t+1}\right)^{-1}\right]\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-bc">
<span class="eqno">(18.34)<a class="headerlink" href="#equation-eqgmm-ex-condexp-bc" title="Permalink to this equation">#</a></span>\[    c_t + k_{t+1} = r_{t+1}k_t + w_t\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-focl">
<span class="eqno">(18.35)<a class="headerlink" href="#equation-eqgmm-ex-condexp-focl" title="Permalink to this equation">#</a></span>\[    w_t = (1 - \alpha)e^{z_t}k_{t}^\alpha\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-fock">
<span class="eqno">(18.36)<a class="headerlink" href="#equation-eqgmm-ex-condexp-fock" title="Permalink to this equation">#</a></span>\[    r_t = \alpha e^{z_t}k_{t}^{\alpha-1}\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-z">
<span class="eqno">(18.37)<a class="headerlink" href="#equation-eqgmm-ex-condexp-z" title="Permalink to this equation">#</a></span>\[    z_{t} = \rho z_{t-1} + (1 - \rho)\mu + \varepsilon_t \quad\text{where}\quad E[\varepsilon_t]=0\]</div>
<p>It is valuable to note first that these unconditional expectations imply minimal restrictions on the stochastic distributions in the model. They only imply a restriction on the first moments of those particular parts of the distributions. Furthermore, because they are unconditional distributions (which is a strong assumption), they also imply restrictions on conditional distributions. Each of these restrictions—both from the unconditional expectations and conditional expectations implications—can be used as moments to identify parameters.</p>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> be the set of variables that are in the information set of the model at the time the expectations operator in the model is formed. Let <span class="math notranslate nohighlight">\(w\in\mathcal{I}\)</span> be the typical element (variable) in the information set. In a cross sectional econometric model, the variables in the information set are <span class="math notranslate nohighlight">\(w\in\mathcal{I}\)</span> that could possibly be related to the dependent variable <span class="math notranslate nohighlight">\(y\)</span> and were determined at the time the expectation was formed. In dynamic models or time series models, variables in the information set include any variables that were determined on or before the period in which the expectation was formed.</p>
<p>The following sequence shows how an unconditional expectation can lead to moments that can identify parameters.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-exexw">
<span class="eqno">(18.38)<a class="headerlink" href="#equation-eqgmm-ex-condexp-exexw" title="Permalink to this equation">#</a></span>\[    E[x] = 0 \Rightarrow E[x|\mathcal{I}] = 0 \Rightarrow Cov[x,w] = 0 \Rightarrow E[xw] = 0\]</div>
<p>The first equation states that the unconditional expectation of <span class="math notranslate nohighlight">\(x\)</span> is zero. This implies that the conditional expectation of <span class="math notranslate nohighlight">\(x\)</span> given anything else in the information set is also zero. This, in turn, implies that the covariance of <span class="math notranslate nohighlight">\(x\)</span> and any element <span class="math notranslate nohighlight">\(w\)</span> of the information set is zero so that the expectation of <span class="math notranslate nohighlight">\(x\)</span> times <span class="math notranslate nohighlight">\(w\)</span> is zero. It is this last equation that generates many of the moments used to identify parameters in GMM. Any variable in the instrument set <span class="math notranslate nohighlight">\(w\in\mathcal{I}\)</span> can generate a moment condition.</p>
<section id="ordinary-least-squares-ols-overidentification">
<span id="secgmm-ex-condexp-ols"></span><h4><span class="section-number">18.5.2.1. </span>Ordinary least squares (OLS): overidentification<a class="headerlink" href="#ordinary-least-squares-ols-overidentification" title="Permalink to this heading">#</a></h4>
<p>The most common method of estimating the parameters of a linear regression is using the ordinary least squares (OLS) estimator. This estimator is just special type of generalized method of moments (GMM) estimator. A simple regression specification in which the dependent variable <span class="math notranslate nohighlight">\(y_i\)</span> is a linear function of two independent variables <span class="math notranslate nohighlight">\(x_{1,i}\)</span> and <span class="math notranslate nohighlight">\(x_{2,i}\)</span> is the following:</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-linreg2">
<span class="eqno">(18.39)<a class="headerlink" href="#equation-eqgmm-ex-condexp-linreg2" title="Permalink to this equation">#</a></span>\[    y_i = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \varepsilon_i \quad\text{where}\quad E\left[\varepsilon_i\right]=0\]</div>
<p>Note that we can solve for the parameters <span class="math notranslate nohighlight">\((\beta_0,\beta_1,\beta_2)\)</span> in a number of ways. And we can do it with only minimal assumptions about the distribution of the error terms <span class="math notranslate nohighlight">\(\varepsilon_i\)</span>.</p>
<p>One way we might choose the parameters is to choose <span class="math notranslate nohighlight">\((\beta_0,\beta_1,\beta_2)\)</span> to minimize the distance between the <span class="math notranslate nohighlight">\(N\)</span> observations of <span class="math notranslate nohighlight">\(y_i\)</span> and the <span class="math notranslate nohighlight">\(N\)</span> predicted values for <span class="math notranslate nohighlight">\(y_i\)</span> given by <span class="math notranslate nohighlight">\(\beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i}\)</span>. You can think of the <span class="math notranslate nohighlight">\(N\)</span> observations of <span class="math notranslate nohighlight">\(y_i\)</span> as <span class="math notranslate nohighlight">\(N\)</span> data moments. And you can think of the <span class="math notranslate nohighlight">\(N\)</span> observations of <span class="math notranslate nohighlight">\(\beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i}\)</span> (the predicted values of <span class="math notranslate nohighlight">\(y_i\)</span>) as <span class="math notranslate nohighlight">\(N\)</span> model moments. The least squares estimator minimizes the sum of squared errors, which is the sum of squared deviations between the <span class="math notranslate nohighlight">\(N\)</span> values of <span class="math notranslate nohighlight">\(y_i\)</span> and  <span class="math notranslate nohighlight">\(\beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i}\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-ols-errs">
<span class="eqno">(18.40)<a class="headerlink" href="#equation-eqgmm-ex-condexp-ols-errs" title="Permalink to this equation">#</a></span>\[    \varepsilon_i = y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-ols-gmmprob">
<span class="eqno">(18.41)<a class="headerlink" href="#equation-eqgmm-ex-condexp-ols-gmmprob" title="Permalink to this equation">#</a></span>\[    \hat{\theta}_{OLS} = \theta:\quad \min_{\theta} \varepsilon^T\, I \, \varepsilon\]</div>
<p>The OLS GMM estimator of the linear regression model is an overidentified GMM estimator, in most cases, because the number of moments <span class="math notranslate nohighlight">\(R=N\)</span> is greater than the number of parameters to be estimated <span class="math notranslate nohighlight">\(K\)</span>.</p>
<p>Let the <span class="math notranslate nohighlight">\(N\times 1\)</span> vector of <span class="math notranslate nohighlight">\(y_i\)</span>’s be <span class="math notranslate nohighlight">\(Y\)</span>. Let the <span class="math notranslate nohighlight">\(N\times 3\)</span> vector of data <span class="math notranslate nohighlight">\((1, x_{1,i}, x_{2,i})\)</span> be <span class="math notranslate nohighlight">\(X\)</span>. And let the vector of three parameters <span class="math notranslate nohighlight">\((\beta_0, \beta_1, \beta_2)\)</span> be <span class="math notranslate nohighlight">\(\beta\)</span>. It can be shown that the OLS estimator for the vector of parameters <span class="math notranslate nohighlight">\(\beta\)</span> is the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-condexp-ols-xxxy">
<span class="eqno">(18.42)<a class="headerlink" href="#equation-eqgmm-ex-condexp-ols-xxxy" title="Permalink to this equation">#</a></span>\[    \hat{\beta}_{OLS} = (X^T X)^{-1}(X^T Y)\]</div>
<p>But you could also just estimate the coefficients using the criterion function in the GMM statement of the problem above. This method is called nonlinear least squares or generalized least squares. Many applications of regression use a weighting matrix in the criterion function that adjusts for issues like heteroskedasticity and autocorrelation.</p>
<p>Many applications use a different distance metric other than the weighted sum of squared errors for the difference in moments. Sum of squared errors puts a large penalty on big differences. Sometimes you might want to maximize the sum of absolute errors, which is sometimes called median regression. You could also minimize the maximum absolute difference in the errors, which is even more extreme than the sum of squared errors on penalizing large differences.</p>
</section>
<section id="linear-regression-by-moment-condition-exact-identification">
<span id="secgmm-ex-condexp-mom"></span><h4><span class="section-number">18.5.2.2. </span>Linear regression by moment condition: exact identification<a class="headerlink" href="#linear-regression-by-moment-condition-exact-identification" title="Permalink to this heading">#</a></h4>
<p>In the linear regression example in the two previous sections, there are three parameters to be estimated <span class="math notranslate nohighlight">\((\beta_0, \beta_1, \beta_2)\)</span>. The OLS approach identifies these three parameters with more than three moments <span class="math notranslate nohighlight">\(R&gt;K\)</span>. The exactly identified GMM approach to estimating the linear regression model comes from the underlying statistical assumptions of the model. We usually assume that the expectation of the error terms is zero. And we assume that the independent variables <span class="math notranslate nohighlight">\((x_{1,i}, x_{2,i})\)</span> are not correlated with the error term <span class="math notranslate nohighlight">\(\varepsilon_i\)</span>. This implies the following three conditions.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-momcond-eps">
<span class="eqno">(18.43)<a class="headerlink" href="#equation-eqgmm-linreg-momcond-eps" title="Permalink to this equation">#</a></span>\[    E\left[\varepsilon\right] = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-momcond-x1">
<span class="eqno">(18.44)<a class="headerlink" href="#equation-eqgmm-linreg-momcond-x1" title="Permalink to this equation">#</a></span>\[    E\left[x_1^T \varepsilon\right] = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-momcond-x2">
<span class="eqno">(18.45)<a class="headerlink" href="#equation-eqgmm-linreg-momcond-x2" title="Permalink to this equation">#</a></span>\[    E\left[x_2^T \varepsilon\right] = 0\]</div>
<p>The data or empirical analogues for these moment conditions are the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-datacond-eps">
<span class="eqno">(18.46)<a class="headerlink" href="#equation-eqgmm-linreg-datacond-eps" title="Permalink to this equation">#</a></span>\[    \frac{1}{N}\sum_{i=1}^N\left[\varepsilon_i\right] = 0 \quad\Rightarrow\quad \sum_{i=1}^N\bigl(y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\bigr) = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-datacond-x1">
<span class="eqno">(18.47)<a class="headerlink" href="#equation-eqgmm-linreg-datacond-x1" title="Permalink to this equation">#</a></span>\[    \frac{1}{N}\sum_{i=1}^N\left[x_{1,i} \varepsilon_i\right] = 0 \quad\Rightarrow\quad \sum_{i=1}^N\Bigl[x_{1,i}\left(y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\right)\Bigr] = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-datacond-x2">
<span class="eqno">(18.48)<a class="headerlink" href="#equation-eqgmm-linreg-datacond-x2" title="Permalink to this equation">#</a></span>\[    \frac{1}{N}\sum_{i=1}^N\left[x_{2,i} \varepsilon_i\right] = 0 \quad\Rightarrow\quad \sum_{i=1}^N\Bigl[x_{2,i}\left(y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\right)\Bigr] = 0\]</div>
<p>Think of the assumed zero correlations in equations <a class="reference internal" href="#equation-eqgmm-linreg-momcond-eps">(18.43)</a>, <a class="reference internal" href="#equation-eqgmm-linreg-momcond-x1">(18.44)</a>, and <a class="reference internal" href="#equation-eqgmm-linreg-momcond-x2">(18.45)</a> as data moments that are all equal to zero. And think of the empirical analogues of those moments as the left-hand-sides of equations <a class="reference internal" href="#equation-eqgmm-linreg-datacond-eps">(18.46)</a>, <a class="reference internal" href="#equation-eqgmm-linreg-datacond-x1">(18.47)</a>, and <a class="reference internal" href="#equation-eqgmm-linreg-datacond-x2">(18.48)</a> as the corresponding model moments. The exactly identified GMM approach to estimating the linear regression model in <a class="reference internal" href="#equation-eqgmm-ex-condexp-linreg2">(18.39)</a> is to choose the parameter vector <span class="math notranslate nohighlight">\(\theta=[\beta_0,\beta_1,\beta_2]\)</span> to minimize the three moment error conditions,</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-linreg-exactprob">
<span class="eqno">(18.49)<a class="headerlink" href="#equation-eqgmm-linreg-exactprob" title="Permalink to this equation">#</a></span>\[\begin{split}    \hat{\theta}_{lin,exact} = \theta:\quad \min_{\theta} e(x|\theta)^T\, W \, e(x|\theta) \\
    \text{where}\quad e(x|\theta)\equiv \begin{bmatrix}
      \sum_{i=1}^N\bigl(y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\bigr) \\
      \sum_{i=1}^N\Bigl[x_{1,i}\left(y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\right)\Bigr] \\
      \sum_{i=1}^N\Bigl[x_{2,i}\left(y_i - \beta_0 - \beta_1 x_{1,i} - \beta_2 x_{2,i}\right)\Bigr]
    \end{bmatrix}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(W\)</span> is some <span class="math notranslate nohighlight">\(3\times 3\)</span> weighting matrix.</p>
</section>
</section>
<section id="brock-and-mirman-1972-dynamic-macroeconomic-model">
<span id="secgmm-ex-bm72"></span><h3><span class="section-number">18.5.3. </span>Brock and Mirman (1972) dynamic macroeconomic model<a class="headerlink" href="#brock-and-mirman-1972-dynamic-macroeconomic-model" title="Permalink to this heading">#</a></h3>
<p>The <span id="id9">[<a class="reference internal" href="../CompMethods_references.html#id8" title="William A. Brock and Leonard J. Mirman. Optimal economic growth and uncertainty: the discounted case. Journal of Economic Theory, 4(3):479-513, June 1972.">Brock and Mirman, 1972</a>]</span> dynamic macroeconomic model was initially used to answer questions about optimal economic growth in a dynamic stochastic environment. However, the model has turned out to be one of the simplest versions of an internally consistent dynamic stochastic general equilibrium model. This model is described and characterized by the following five equations. You will use this model as an example for GMM estimation in <a class="reference internal" href="#ExercStructEst_GMM_BM72"><span class="std std-numref">Exercise 18.2</span></a>.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-bm72-eulc">
<span class="eqno">(18.50)<a class="headerlink" href="#equation-eqgmm-ex-bm72-eulc" title="Permalink to this equation">#</a></span>\[    \left(c_t\right)^{-1} = \beta E\left[r_{t+1}\left(c_{t+1}\right)^{-1}\right]\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-bm72-bc">
<span class="eqno">(18.51)<a class="headerlink" href="#equation-eqgmm-ex-bm72-bc" title="Permalink to this equation">#</a></span>\[    c_t + k_{t+1} = r_{t+1}k_t + w_t\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-bm72-focl">
<span class="eqno">(18.52)<a class="headerlink" href="#equation-eqgmm-ex-bm72-focl" title="Permalink to this equation">#</a></span>\[    w_t = (1 - \alpha)e^{z_t}k_{t}^\alpha\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-bm72-fock">
<span class="eqno">(18.53)<a class="headerlink" href="#equation-eqgmm-ex-bm72-fock" title="Permalink to this equation">#</a></span>\[    r_t = \alpha e^{z_t}k_{t}^{\alpha-1}\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-ex-bm72-z">
<span class="eqno">(18.54)<a class="headerlink" href="#equation-eqgmm-ex-bm72-z" title="Permalink to this equation">#</a></span>\[    z_{t} = \rho z_{t-1} + (1 - \rho)\mu + \varepsilon_t \quad\text{where}\quad E[\varepsilon_t]=0\]</div>
</section>
<section id="hansen-and-singleton-1982">
<span id="secgmm-ex-hs82"></span><h3><span class="section-number">18.5.4. </span>Hansen and Singleton (1982)<a class="headerlink" href="#hansen-and-singleton-1982" title="Permalink to this heading">#</a></h3>
<p><span id="id10">[<a class="reference internal" href="../CompMethods_references.html#id37" title="Lars Peter Hansen. Large sample properties of generalized method of moments estimators. Econometrica, 50(4):1029-1054, July 1982.">Hansen, 1982</a>]</span> was the first paper to formalize the generalized method of moments (GMM) estimation method. And <span id="id11">[<a class="reference internal" href="../CompMethods_references.html#id38" title="Lars Peter Hansen and Kenneth J. Singleton. Generalized instrumental variables estimation of nonlinear rational expectations models. Econometrica, 50(5):1269-1286, September 1982.">Hansen and Singleton, 1982</a>]</span> was the first finacial macroeconomic application of the method. In the previous section, we used the <span id="id12">[<a class="reference internal" href="../CompMethods_references.html#id8" title="William A. Brock and Leonard J. Mirman. Optimal economic growth and uncertainty: the discounted case. Journal of Economic Theory, 4(3):479-513, June 1972.">Brock and Mirman, 1972</a>]</span> model because it is such a simple dynamic stochastic macroeconomic model. <span id="id13">[<a class="reference internal" href="../CompMethods_references.html#id38" title="Lars Peter Hansen and Kenneth J. Singleton. Generalized instrumental variables estimation of nonlinear rational expectations models. Econometrica, 50(5):1269-1286, September 1982.">Hansen and Singleton, 1982</a>]</span> use a slightly more complex dynamic stochastic macroeconomic model with a structure that applied more closely to data on asset prices.</p>
<p><span id="id14">[<a class="reference internal" href="../CompMethods_references.html#id38" title="Lars Peter Hansen and Kenneth J. Singleton. Generalized instrumental variables estimation of nonlinear rational expectations models. Econometrica, 50(5):1269-1286, September 1982.">Hansen and Singleton, 1982</a>]</span> provide of comparison of their GMM estimates to the corresponding estimates implied by maximum likelihood estimation. They highlight the advantage of GMM that it requires fewer distributional assumptions and only requires the orthogonality conditions (unconditional and conditional expectations) of the model rather than the full solution of the model in rational expectations models.</p>
</section>
</section>
<section id="secgmm-ident">
<span id="identification"></span><h2><span class="section-number">18.6. </span>Identification<a class="headerlink" href="#secgmm-ident" title="Permalink to this heading">#</a></h2>
<p>An issue that we saw in the examples from Section <a class="reference internal" href="#secgmm-ex"><span class="std std-ref">Code Examples</span></a> is that there is some science as well as some art in choosing moments to identify the parameters in a GMM estimation.</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> parameters were identified more precisely when using the two-step estimator of the optimal weighting matrix instead of the identity matrix.</p></li>
<li><p>The overidentified four-moment model of total scores produced much smaller standard errors for both <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> than did the two-moment model.</p></li>
</ul>
<p>Suppose the parameter vector <span class="math notranslate nohighlight">\(\theta\)</span> has <span class="math notranslate nohighlight">\(K\)</span> elements, or rather, <span class="math notranslate nohighlight">\(K\)</span> parameters to be estimated. In order to estimate <span class="math notranslate nohighlight">\(\theta\)</span> by GMM, you must have at least as many moments as parameters to estimate <span class="math notranslate nohighlight">\(R\geq K\)</span>. If you have exactly as many moments as parameters to be estimated <span class="math notranslate nohighlight">\(R=K\)</span>, the model is said to be <em>exactly identified</em>. If you have more moments than parameters to be estimated <span class="math notranslate nohighlight">\(R&gt;K\)</span>, the model is said to be <em>overidentified</em>. If you have fewer moments than parameters to be estimated <span class="math notranslate nohighlight">\(R&lt;K\)</span>, the model is said to be <em>underidentified</em>. There are good reasons to overidentify <span class="math notranslate nohighlight">\(R&gt;K\)</span> the model in GMM estimation as we saw in the previous example. The main reason is that not all moments are orthogonal. That is, some moments convey roughly the same information about the data and, therefore, do not separately identify any extra parameters. So a good GMM model often is overidentified <span class="math notranslate nohighlight">\(R&gt;K\)</span>.</p>
<p>One last point about GMM regards moment selection and verification of results. The real world has an infinite supply of potential moments that describe some part of the data. Choosing moments to estimate parameters by GMM requires understanding of the model, intuition about its connections to the real world, and artistry. A good GMM estimation will include moments that have some relation to or story about their connection to particular parameters of the model to be estimated. In addition, a good verification of a GMM estimation is to take some moment from the data that was not used in the estimation and see how well the corresponding moment from the estimated model matches that <em>outside moment</em>.</p>
</section>
<section id="exercises">
<span id="secgmm-exerc"></span><h2><span class="section-number">18.7. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h2>
<div class="exercise green admonition" id="ExercStructEst_GMM_incdist">

<p class="admonition-title"><span class="caption-number">Exercise 18.1 </span> (Matching the US income distribution by GMM)</p>
<section id="exercise-content">
<p>In this exercise, you will use the comma-delimited data file <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/data/gmm/hh_inc_synth.txt"><code class="docutils literal notranslate"><span class="pre">hh_inc_synth.txt</span></code></a> in the <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/tree/main/data/gmm"><code class="docutils literal notranslate"><span class="pre">./data/gmm/</span></code></a> folder of the GitHub repository for this book, which contains the 121,085 observations (synthetic) on household US income. <a class="reference internal" href="#tabgmmincmoms"><span class="std std-numref">Table 18.1</span></a> displays histogram counts and population percentages (moments) for each income range. The first column in the data file gives the percent of the population in each income bin (the third column of <a class="reference internal" href="#tabgmmincmoms"><span class="std std-numref">Table 18.1</span></a>). The second column in the data file has the midpoint of each income bin. So the midpoint of the first income bin of all household incomes less than $5,000 is $2,500. You may want to use the <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/code/gmm/distributions.py"><code class="docutils literal notranslate"><span class="pre">distributions.py</span></code></a> module in the <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/code/mle/"><code class="docutils literal notranslate"><span class="pre">./code/gmm/</span></code></a> folder of the GitHub repository for this online book.</p>
<ol class="arabic simple">
<li><p>Use the <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.histogram.html"><code class="docutils literal notranslate"><span class="pre">numpy.histogram()</span></code></a> function to create the population count and population percentage moments in <a class="reference internal" href="#tabgmmincmoms"><span class="std std-numref">Table 18.1</span></a> from the synthetic household income data in comma-delimited text file <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/data/gmm/hh_inc_synth.txt"><code class="docutils literal notranslate"><span class="pre">hh_inc_synth.txt</span></code></a> by inputing the appropriate list of bin edges for the <code class="docutils literal notranslate"><span class="pre">bins</span></code> argument of the <code class="docutils literal notranslate"><span class="pre">numpy.histogram()</span></code> function.</p></li>
<li><p>Plot the histogram of the data <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/data/gmm/hh_inc_synth.txt"><code class="docutils literal notranslate"><span class="pre">hh_inc_synth.txt</span></code></a> using the bins described in the first column of <a class="reference internal" href="#tabgmmincmoms"><span class="std std-numref">Table 18.1</span></a>, which you used as an input to parts (1) and (2), and the height being the density (not the count) such that the area of the histogram bars sums to one (use the <code class="docutils literal notranslate"><span class="pre">weights</span></code> option rather than the <code class="docutils literal notranslate"><span class="pre">density</span></code> option in <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html"><code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.hist</span></code></a> because your bin widths are not equal). List the dollar amounts on the <span class="math notranslate nohighlight">\(x\)</span>-axis as thousands of dollars. That is, divide them by 1,000 to put them in units of thousands of dollars ($000s). Even though the top bin is listed as $250,000 and above in <a class="reference internal" href="#tabgmmincmoms"><span class="std std-numref">Table 18.1</span></a>, the synthetic data are top-coded at $350,000, so set to last bin edge to $350,000. (It doesn’t look very good graphing it between 0 and <span class="math notranslate nohighlight">\(\infty\)</span>.) The equation for the weight of each observation <span class="math notranslate nohighlight">\(i\)</span> that normalizes a variable bin-width histogram to be a density is <a class="reference internal" href="#equation-eqgmm-exc-incmoms-wgt">(18.55)</a>, where <span class="math notranslate nohighlight">\(N\)</span> is the number of observations in the data and <span class="math notranslate nohighlight">\(bin\_width_j\)</span> is the width of the histogram bin that observation <span class="math notranslate nohighlight">\(i\)</span> is part of. In summary, your histogram should have 42 bars. The first 40 bars for the lowest income bins should be the same width. However, the last two bars should be different widths from each other and from the rest of the bars. It should look like <a class="reference internal" href="#figgmm-hist-inc"><span class="std std-numref">Figure 18.6</span></a>. [Hint: look at the <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html"><code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot.hist</span></code></a> command option of <code class="docutils literal notranslate"><span class="pre">bins</span></code> and submit a list of bin edges for the <code class="docutils literal notranslate"><span class="pre">bins</span></code> option.]</p></li>
</ol>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-incmoms-wgt">
<span class="eqno">(18.55)<a class="headerlink" href="#equation-eqgmm-exc-incmoms-wgt" title="Permalink to this equation">#</a></span>\[    weight_i = \frac{1}{N \times bin\_width_j} \:\:\text{for all}\:\: i \:\:\text{in histogram bin}\:\: j\]</div>
<ol class="arabic simple" start="3">
<li><p>Using GMM, fit the two-parameter lognormal <span class="math notranslate nohighlight">\(LN(x|\mu,\sigma)\)</span> distribution defined in section <a class="reference internal" href="MLE.html#secmle-gbfam-ln"><span class="std std-ref">Lognormal distribution (LN, 2 parameters)</span></a> of the <a class="reference internal" href="MLE.html#chap-mle"><span class="std std-ref">Maximum Likelihood Estimation</span></a> chapter to the distribution of household income data using the moments from the data file. Make sure to try various initial guesses. (HINT: <span class="math notranslate nohighlight">\(\mu_0=\ln(avg.\:inc.)\)</span> might be good.) For your weighting matrix <span class="math notranslate nohighlight">\(W\)</span>, use a <span class="math notranslate nohighlight">\(42\times 42\)</span> diagonal matrix in which the diagonal non-zero elements are the population percentage moments from the data file. This will put the most weight on the moments with the largest percent of the population. Report your estimated values for <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}\)</span>, as well as the value of the minimized criterion function <span class="math notranslate nohighlight">\(e(x|\hat{\theta})^T \, W \, e(x|\hat{\theta})\)</span>. Plot the histogram from part (2) overlayed with a line representing the implied histogram from your estimated lognormal (LN) distribution. Each point on the line is the midpoint of the bin and the implied height of the bin. Do not forget to divide the values for your last two moments by 10 and 20, respectively, so that they match up with the histogram.</p></li>
<li><p>Using GMM, fit the gamma <span class="math notranslate nohighlight">\(GA(x|\alpha,\beta)\)</span> distribution defined in section <a class="reference internal" href="MLE.html#secmle-gbfam-ga"><span class="std std-ref">Gamma distribution (GA, 2 parameters)</span></a> of the <a class="reference internal" href="MLE.html#chap-mle"><span class="std std-ref">Maximum Likelihood Estimation</span></a> chapter to the distribution of household income data using the moments from the data file. Use <span class="math notranslate nohighlight">\(\alpha_0=3\)</span> and <span class="math notranslate nohighlight">\(\beta_0=20,000\)</span> as your initial guess. These initial guesses come from the property of the gamma (GA) distribution that <span class="math notranslate nohighlight">\(E(x)=\alpha\beta\)</span> and <span class="math notranslate nohighlight">\(Var(x)=\alpha\beta^2\)</span>. Report your estimated values for <span class="math notranslate nohighlight">\(\hat{\alpha}\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta}\)</span>, as well as the value of the minimized criterion function <span class="math notranslate nohighlight">\(e(x|\hat{\theta})^T \, W \, e(x|\hat{\theta})\)</span>. Use the same weighting matrix as in part (3). Plot the histogram from part (2) overlayed with a line representing the implied histogram from your estimated gamma (GA) distribution. Do not forget to divide the values for your last two moments by 10 and 20, respectively, so that they match up with the histogram.</p></li>
<li><p>Plot the histogram from part (2) overlayed with the line representing the implied histogram from your estimated lognormal (LN) distribution from part (3) and the line representing the implied histogram from your estimated gamma (GA) distribution from part (4). What is the most precise way to tell which distribution fits the data the best? Which estimated distribution—<span class="math notranslate nohighlight">\(LN\)</span> or <span class="math notranslate nohighlight">\(GA\)</span>—fits the data best?</p></li>
<li><p>Repeat your estimation of the <span class="math notranslate nohighlight">\(GA\)</span> distribution from part (4), but use the two-step estimator for the optimal weighting matrix <span class="math notranslate nohighlight">\(\hat{W}_{twostep}\)</span>. Do your estimates for <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> change much? How can you compare the goodness of fit of this estimated distribution versus the goodness of fit of the estimated distribution in part (4)?</p></li>
</ol>
<table class="table" id="tabgmmincmoms">
<caption><span class="caption-number">Table 18.1 </span><span class="caption-text">Distribution of Household Money Income by Selected Income Range, 2011. Source: 2011 CPS household income count data Current Population Survey (2012, Table HINC-01).</span><a class="headerlink" href="#tabgmmincmoms" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Income</p></th>
<th class="head"><p># housholds</p></th>
<th class="head"><p>% of</p></th>
</tr>
<tr class="row-even"><th class="head"><p>range</p></th>
<th class="head"><p>(000s)</p></th>
<th class="head"><p>population</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd"><td><p>All households</p></td>
<td><p>121,084</p></td>
<td><p>100.0</p></td>
</tr>
<tr class="row-even"><td><p>Less than $5,000</p></td>
<td><p>4,261</p></td>
<td><p>3.5</p></td>
</tr>
<tr class="row-odd"><td><p>$5,000 to $9,999</p></td>
<td><p>4,972</p></td>
<td><p>4.1</p></td>
</tr>
<tr class="row-even"><td><p>$10,000 to $14,999</p></td>
<td><p>7,127</p></td>
<td><p>5.9</p></td>
</tr>
<tr class="row-odd"><td><p>$15,000 to $19,999</p></td>
<td><p>6,882</p></td>
<td><p>5.7</p></td>
</tr>
<tr class="row-even"><td><p>$20,000 to $24,999</p></td>
<td><p>7,095</p></td>
<td><p>5.9</p></td>
</tr>
<tr class="row-odd"><td><p>$25,000 to $29,999</p></td>
<td><p>6,591</p></td>
<td><p>5.4</p></td>
</tr>
<tr class="row-even"><td><p>$30,000 to $34,999</p></td>
<td><p>6,667</p></td>
<td><p>5.5</p></td>
</tr>
<tr class="row-odd"><td><p>$35,000 to $39,999</p></td>
<td><p>6,136</p></td>
<td><p>5.1</p></td>
</tr>
<tr class="row-even"><td><p>$40,000 to $44,999</p></td>
<td><p>5,795</p></td>
<td><p>4.8</p></td>
</tr>
<tr class="row-odd"><td><p>$45,000 to $49,999</p></td>
<td><p>4,945</p></td>
<td><p>4.1</p></td>
</tr>
<tr class="row-even"><td><p>$50,000 to $54,999</p></td>
<td><p>5,170</p></td>
<td><p>4.3</p></td>
</tr>
<tr class="row-odd"><td><p>$55,000 to $59,999</p></td>
<td><p>4,250</p></td>
<td><p>3.5</p></td>
</tr>
<tr class="row-even"><td><p>$60,000 to $64,999</p></td>
<td><p>4,432</p></td>
<td><p>3.7</p></td>
</tr>
<tr class="row-odd"><td><p>$65,000 to $69,999</p></td>
<td><p>3,836</p></td>
<td><p>3.2</p></td>
</tr>
<tr class="row-even"><td><p>$70,000 to $74,999</p></td>
<td><p>3,606</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>$75,000 to $79,999</p></td>
<td><p>3,452</p></td>
<td><p>2.9</p></td>
</tr>
<tr class="row-even"><td><p>$80,000 to $84,999</p></td>
<td><p>3,036</p></td>
<td><p>2.5</p></td>
</tr>
<tr class="row-odd"><td><p>$85,000 to $89,999</p></td>
<td><p>2,566</p></td>
<td><p>2.1</p></td>
</tr>
<tr class="row-even"><td><p>$90,000 to $94,999</p></td>
<td><p>2,594</p></td>
<td><p>2.1</p></td>
</tr>
<tr class="row-odd"><td><p>$95,000 to $99,999</p></td>
<td><p>2,251</p></td>
<td><p>1.9</p></td>
</tr>
<tr class="row-even"><td><p>$100,000 to $104,999</p></td>
<td><p>2,527</p></td>
<td><p>2.1</p></td>
</tr>
<tr class="row-odd"><td><p>$105,000 to $109,999</p></td>
<td><p>1,771</p></td>
<td><p>1.5</p></td>
</tr>
<tr class="row-even"><td><p>$110,000 to $114,999</p></td>
<td><p>1,723</p></td>
<td><p>1.4</p></td>
</tr>
<tr class="row-odd"><td><p>$115,000 to $119,999</p></td>
<td><p>1,569</p></td>
<td><p>1.3</p></td>
</tr>
<tr class="row-even"><td><p>$120,000 to $124,999</p></td>
<td><p>1,540</p></td>
<td><p>1.3</p></td>
</tr>
<tr class="row-odd"><td><p>$125,000 to $129,999</p></td>
<td><p>1,258</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-even"><td><p>$130,000 to $134,999</p></td>
<td><p>1,211</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>$135,000 to $139,999</p></td>
<td><p>918</p></td>
<td><p>0.8</p></td>
</tr>
<tr class="row-even"><td><p>$140,000 to $144,999</p></td>
<td><p>1,031</p></td>
<td><p>0.9</p></td>
</tr>
<tr class="row-odd"><td><p>$145,000 to $149,999</p></td>
<td><p>893</p></td>
<td><p>0.7</p></td>
</tr>
<tr class="row-even"><td><p>$150,000 to $154,999</p></td>
<td><p>1,166</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>$155,000 to $159,999</p></td>
<td><p>740</p></td>
<td><p>0.6</p></td>
</tr>
<tr class="row-even"><td><p>$160,000 to $164,999</p></td>
<td><p>697</p></td>
<td><p>0.6</p></td>
</tr>
<tr class="row-odd"><td><p>$165,000 to $169,999</p></td>
<td><p>610</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-even"><td><p>$170,000 to $174,999</p></td>
<td><p>617</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-odd"><td><p>$175,000 to $179,999</p></td>
<td><p>530</p></td>
<td><p>0.4</p></td>
</tr>
<tr class="row-even"><td><p>$180,000 to $184,999</p></td>
<td><p>460</p></td>
<td><p>0.4</p></td>
</tr>
<tr class="row-odd"><td><p>$185,000 to $189,999</p></td>
<td><p>363</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-even"><td><p>$190,000 to $194,999</p></td>
<td><p>380</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-odd"><td><p>$195,000 to $199,999</p></td>
<td><p>312</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-even"><td><p>$200,000 to $249,999</p></td>
<td><p>2,297</p></td>
<td><p>1.9</p></td>
</tr>
<tr class="row-odd"><td><p>$250,000 and over</p></td>
<td><p>2,808</p></td>
<td><p>2.3</p></td>
</tr>
<tr class="row-even"><td><p>Mean income</p></td>
<td><p>$69,677</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Median income</p></td>
<td><p>$50,054</p></td>
<td></td>
</tr>
</tbody>
</table>
<figure class="align-default" id="figgmm-hist-inc">
<a class="reference internal image-reference" href="../_images/hist_inc.png"><img alt="../_images/hist_inc.png" src="../_images/hist_inc.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18.6 </span><span class="caption-text">Histogram of US household income: <span class="math notranslate nohighlight">\(N=121,085\)</span>. Source: 2011 CPS household income count data <span id="id15">[<a class="reference internal" href="../CompMethods_references.html#id22" title="Current Population Survey. 2012 annual social and economic (asec) supplement. Technical Report, Bureau of the Census and Bureau of Labor Statistics, 2012.">Current Population Survey, 2012</a>]</span>.</span><a class="headerlink" href="#figgmm-hist-inc" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</div>
<div class="exercise green admonition" id="ExercStructEst_GMM_BM72">

<p class="admonition-title"><span class="caption-number">Exercise 18.2 </span> (Estimating the Brock and Mirman, 1972 model by GMM)</p>
<section id="exercise-content">
<p>You can observe time series data in an economy for the following variables: <span class="math notranslate nohighlight">\((c_t, k_t, w_t, r_t)\)</span>. Data on <span class="math notranslate nohighlight">\((c_t, k_t, w_t, r_t)\)</span> can be loaded from the file <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/blob/main/data/gmm/MacroSeries.txt"><code class="docutils literal notranslate"><span class="pre">MacroSeries.txt</span></code></a> in the <a class="reference external" href="https://github.com/OpenSourceEcon/CompMethods/tree/main/data/gmm"><code class="docutils literal notranslate"><span class="pre">./data/gmm/</span></code></a> folder of the GitHub repository for this book. This file is a comma separated text file with no labels. The variables are ordered as <span class="math notranslate nohighlight">\((c_t, k_t, w_t, r_t)\)</span>. These data have 100 periods, which are quarterly (25 years). Suppose you think that the data are generated by a process similar to the <span id="id16">[<a class="reference internal" href="../CompMethods_references.html#id8" title="William A. Brock and Leonard J. Mirman. Optimal economic growth and uncertainty: the discounted case. Journal of Economic Theory, 4(3):479-513, June 1972.">Brock and Mirman, 1972</a>]</span> model. A simplified set of characterizing equations of the Brock and Mirman (1972) model are the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-eulc">
<span class="eqno">(18.56)<a class="headerlink" href="#equation-eqgmm-exc-bm72-eulc" title="Permalink to this equation">#</a></span>\[    \left(c_t\right)^{-1} = \beta E\left[r_{t+1}\left(c_{t+1}\right)^{-1}\right]\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-bc">
<span class="eqno">(18.57)<a class="headerlink" href="#equation-eqgmm-exc-bm72-bc" title="Permalink to this equation">#</a></span>\[    c_t + k_{t+1} = r_{t+1}k_t + w_t\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-focl">
<span class="eqno">(18.58)<a class="headerlink" href="#equation-eqgmm-exc-bm72-focl" title="Permalink to this equation">#</a></span>\[    w_t = (1 - \alpha)e^{z_t}k_{t}^\alpha\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-fock">
<span class="eqno">(18.59)<a class="headerlink" href="#equation-eqgmm-exc-bm72-fock" title="Permalink to this equation">#</a></span>\[    r_t = \alpha e^{z_t}k_{t}^{\alpha-1}\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-z">
<span class="eqno">(18.60)<a class="headerlink" href="#equation-eqgmm-exc-bm72-z" title="Permalink to this equation">#</a></span>\[    z_{t} = \rho z_{t-1} + (1 - \rho)\mu + \varepsilon_t \quad\text{where}\quad E[\varepsilon_t]=0\]</div>
<p>The variable <span class="math notranslate nohighlight">\(c_t\)</span> is aggregate consumption in period <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(k_{t+1}\)</span> is total household savings and investment in period <span class="math notranslate nohighlight">\(t\)</span> for which they receive a return in the next period (this model assumes full depreciation of capital). The wage per unit of labor in period <span class="math notranslate nohighlight">\(t\)</span> is <span class="math notranslate nohighlight">\(w_t\)</span> and the interest rate or rate of return on investment is <span class="math notranslate nohighlight">\(r_t\)</span>. Total factor productivity is <span class="math notranslate nohighlight">\(z_t\)</span>, which follows an AR(1) process given in <a class="reference internal" href="#equation-eqgmm-exc-bm72-z">(18.60)</a>. The rest of the symbols in the equations are parameters that must be estimated or must be otherwise given <span class="math notranslate nohighlight">\((\alpha,\beta,\rho,\mu,\sigma)\)</span>. The constraints on these parameters are the following.</p>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-cstr">
<span class="eqno">(18.61)<a class="headerlink" href="#equation-eqgmm-exc-bm72-cstr" title="Permalink to this equation">#</a></span>\[    \alpha,\beta\in(0,1),\quad \mu,\sigma &gt; 0,\quad \rho\in(-1,1)\]</div>
<p>Assume that the first observation in the data file variables is <span class="math notranslate nohighlight">\(t=1\)</span>. Let <span class="math notranslate nohighlight">\(k_1\)</span> be the first observation in the data file for the variable <span class="math notranslate nohighlight">\(k_t\)</span>.</p>
<ol class="arabic simple">
<li><p>Estimate <span class="math notranslate nohighlight">\(\alpha\)</span>, <span class="math notranslate nohighlight">\(\rho\)</span>, and <span class="math notranslate nohighlight">\(\mu\)</span> by GMM using the unconditional moment conditions that <span class="math notranslate nohighlight">\(E[\ve_t]=0\)</span> and <span class="math notranslate nohighlight">\(E[\beta r_{t+1}c_t/c_{t+1} - 1]=0\)</span>. Assume <span class="math notranslate nohighlight">\(\beta=0.99\)</span>. Use the <span class="math notranslate nohighlight">\(4\times 4\)</span> identity matrix <span class="math notranslate nohighlight">\(I(4)\)</span> as your estimator of the optimal weighting matrix. Use the following four moment conditions <a class="reference internal" href="#equation-eqgmm-exc-bm72-zmom1">(18.62)</a>, <a class="reference internal" href="#equation-eqgmm-exc-bm72-zmom2">(18.63)</a>, <a class="reference internal" href="#equation-eqgmm-exc-bm72-mainmom1">(18.64)</a>, and <a class="reference internal" href="#equation-eqgmm-exc-bm72-mainmom2">(18.65)</a> to estimate the four parameters. Report your estimated parameter values <span class="math notranslate nohighlight">\((\hat{\alpha},\hat{\rho},\hat{\mu})\)</span> and the value of your minimized criterion function. The estimation inside each iteration of the minimizer of the GMM objective function is the following.</p>
<ul class="simple">
<li><p>Given a guess for <span class="math notranslate nohighlight">\((\alpha,\rho,\mu)\)</span> and data <span class="math notranslate nohighlight">\((c_t, k_t, w_t, r_t)\)</span>, use <a class="reference internal" href="#equation-eqgmm-exc-bm72-fock">(18.59)</a> to back out an implied series for <span class="math notranslate nohighlight">\(z_t\)</span>.</p></li>
<li><p>Given <span class="math notranslate nohighlight">\(z_t\)</span>, parameters <span class="math notranslate nohighlight">\((\alpha,\rho,\mu)\)</span> and data <span class="math notranslate nohighlight">\((c_t, k_t, w_t, r_t)\)</span>, calculate four empirical analogues of the moment conditions <a class="reference internal" href="#equation-eqgmm-exc-bm72-zmom1">(18.62)</a>, <a class="reference internal" href="#equation-eqgmm-exc-bm72-zmom2">(18.63)</a>, <a class="reference internal" href="#equation-eqgmm-exc-bm72-mainmom1">(18.64)</a>, and <a class="reference internal" href="#equation-eqgmm-exc-bm72-mainmom2">(18.65)</a>.</p></li>
<li><p>Update guesses for parameters <span class="math notranslate nohighlight">\((\alpha,\rho,\mu)\)</span> until minimum criterion value is found.</p></li>
</ul>
</li>
</ol>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-zmom1">
<span class="eqno">(18.62)<a class="headerlink" href="#equation-eqgmm-exc-bm72-zmom1" title="Permalink to this equation">#</a></span>\[    E\Bigl[z_{t+1} - \rho z_t - (1-\rho)\mu\Bigr] = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-zmom2">
<span class="eqno">(18.63)<a class="headerlink" href="#equation-eqgmm-exc-bm72-zmom2" title="Permalink to this equation">#</a></span>\[    E\biggl[\Bigl(z_{t+1} - \rho z_t - (1-\rho)\mu\Bigr)z_t\biggr] = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-mainmom1">
<span class="eqno">(18.64)<a class="headerlink" href="#equation-eqgmm-exc-bm72-mainmom1" title="Permalink to this equation">#</a></span>\[    E\left[\beta\alpha e^{z_{t+1}}k_{t+1}^{\alpha-1}\frac{c_t}{c_{t+1}} - 1\right] = 0\]</div>
<div class="math notranslate nohighlight" id="equation-eqgmm-exc-bm72-mainmom2">
<span class="eqno">(18.65)<a class="headerlink" href="#equation-eqgmm-exc-bm72-mainmom2" title="Permalink to this equation">#</a></span>\[    E\left[\left(\beta\alpha e^{z_{t+1}}k_{t+1}^{\alpha-1}\frac{c_t}{c_{t+1}} - 1\right)w_t\right] = 0\]</div>
<ol class="arabic simple" start="2">
<li><p>Compute the two-step GMM estimator of <span class="math notranslate nohighlight">\((\alpha,\rho,\mu)\)</span> and use the finite difference Jacobian method for the estimator of the variance-covariance of the two-step GMM point estimates <span class="math notranslate nohighlight">\((\hat{\alpha}, \hat{\rho}, \hat{\mu})\)</span>. Report the GMM two-step estimates for the parameters and their standard errors.</p></li>
</ol>
</section>
</div>
</section>
<section id="footnotes">
<span id="secgmmfootnotes"></span><h2><span class="section-number">18.8. </span>Footnotes<a class="headerlink" href="#footnotes" title="Permalink to this heading">#</a></h2>
<p>The footnotes from this chapter.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./struct_est"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="MLE.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">17. </span>Maximum Likelihood Estimation</p>
      </div>
    </a>
    <a class="right-next"
       href="SMM.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">19. </span>Simulated Method of Moments Estimation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-vs-mle-strengths-and-weaknesses">18.1. GMM vs. MLE: Strengths and weaknesses</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-strengths">18.1.1. MLE strengths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-weaknesses">18.1.2. MLE weaknesses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-strengths">18.1.3. GMM strengths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-weaknesses">18.1.4. GMM weaknesses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-questions-when-deciding-between-mle-and-gmm">18.1.5. Key questions when deciding between MLE and GMM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gmm-estimator">18.2. The GMM estimator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-weighting-matrix-w">18.3. The weighting matrix (W)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-identity-matrix-w-i">18.3.1. The identity matrix (W=I)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-step-variance-covariance-estimator-of-w">18.3.2. Two-step variance-covariance estimator of W</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iterated-variance-covariance-estimator-of-w">18.3.3. Iterated variance-covariance estimator of W</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#newey-west-consistent-estimator-of-omega-and-w">18.3.4. Newey-West consistent estimator of <span class="math notranslate nohighlight">\(\Omega\)</span> and W</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-covariance-estimator-of-hat-theta">18.4. Variance-Covariance Estimator of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-examples">18.5. Code Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-a-truncated-normal-to-intermediate-macroeconomics-test-scores">18.5.1. Fitting a truncated normal to intermediate macroeconomics test scores</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#two-moments-identity-weighting-matrix">18.5.1.1. Two moments, identity weighting matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#two-moments-two-step-weighting-matrix">18.5.1.2. Two moments, two-step weighting matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#four-moments-identity-weighting-matrix">18.5.1.3. Four moments, identity weighting matrix</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#four-moments-two-step-weighting-matrix">18.5.1.4. Four moments, two-step weighting matrix</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unconditional-and-conditional-expectations-instruments-and-moments">18.5.2. Unconditional and conditional expectations, instruments, and moments</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinary-least-squares-ols-overidentification">18.5.2.1. Ordinary least squares (OLS): overidentification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-by-moment-condition-exact-identification">18.5.2.2. Linear regression by moment condition: exact identification</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brock-and-mirman-1972-dynamic-macroeconomic-model">18.5.3. Brock and Mirman (1972) dynamic macroeconomic model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hansen-and-singleton-1982">18.5.4. Hansen and Singleton (1982)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#secgmm-ident">18.6. Identification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">18.7. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#footnotes">18.8. Footnotes</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Richard W. Evans
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>